[ { "title": "앞으로 가야하는 방향", "url": "/posts/%EA%B0%80%EC%95%BC%ED%95%98%EB%8A%94-%EB%B0%A9%ED%96%A5/", "categories": "Thinking", "tags": "mind-control", "date": "2025-12-07 09:00:00 +0000", "snippet": "하고 싶은 기술 스택 웹, 앱 어플리케이션 : spring react 데이터 엔지니어링 : spark, airflow, emr, kafka-streaming, spark-streaming, CDC 솔루션 등등 이제 하면 됨. AI 엔지니어링 : rag, openai 미지의 세계. 인강이나 듣자 DevOps 엔지니어링 : cloud 기반 operation settings 이건 위에 하면서 같이 하면 될듯 요렇게 40살 전까지 그럴듯하게 다 스택을 채울 수 있을까요~" }, { "title": "AWS 연구, EC2 ALB EMR 등", "url": "/posts/AWS-%EC%97%B0%EA%B5%AC%EA%B3%BC%EC%A0%9C/", "categories": "Blogging, DevOps", "tags": "cloud, aws", "date": "2025-12-02 03:00:00 +0000", "snippet": "Https 설정하기 옛날에 nfront 하듯이, ALB가 전담하게 시킬 수 있다. 인증서 만들기. AWS Certificate 가서 만들어 ALB 생성. ec2 -&gt; Loadbalancer 하면서 여기에다가 규칙같은것 넣을 수 있고, 어떤 subnet 에 만들지 정할 수 있고 등등 https 인증서도 이식함 일단 만들고 listener 추가 뒤 rule 변경하면 하나의 ip 로 개발, 스테이지, 상용 공유하면서 돈 절약 가능함. ec2 그룹으로 만들어놓고, target group 같은거 매칭해준다. vpc subnet 네트워크 핵심인데 정리하는 대로 추가 예정사스 갖다쓰면 2배정도 비싸다 내돈이면 ec2 받아서 직접 설치해야 할 듯.Loadbalancer Application Loadbalancer 는 vpc 대역만 같으면 어느 서브넷이건 전달 될 수 있다. Network Loadbalancer 는 같은 vpc 는 당연하고, 같은 “Availability Zone” 에 있어야한다. 2a, 2b, 2c" }, { "title": "팀 한번 옮기며 깨달은 바들 정리", "url": "/posts/%ED%8C%80-%ED%95%9C%EB%B2%88-%EC%98%AE%EA%B8%B0%EB%A9%B0-%EA%B9%A8%EB%8B%AC%EC%9D%80-%EB%B0%94%EB%93%A4-%EC%A0%95%EB%A6%AC/", "categories": "Thinking, Mind-Control", "tags": "mind-control", "date": "2025-11-03 09:00:00 +0000", "snippet": "자주 변하는 서비스를 만들며 구체적인 팁들 데이터 구조 설계할 떄 가능하면 뭐든지 object 로 만들것 그니까 뭐 List&lt;String&gt; 이런건 하면 안됨 뭔가 string 이랑 같이 엮여서 데이터 하나 추가해달라고 하는 경우가 많은듯. List&lt;Dto&gt; 를 써야함 뭔가 fetch 해오는 메서드 만들 때, 뭔가 객체를 리턴하는거보다 key 값만 리턴하고 필요하면 추가 조회하는 형태의 메서드 구성이 좋은듯. 쿼리 한두번 더 호출하겠지만, 재사용성이 높아짐. 객체 리턴했다가 다른곳에서 쓰기 어려운거면 고치기도 힘들고 새로만들게됨.-&gt; 개판됨 보통 이런게 일어날까? 싶은건 일어남. 기획 &amp; 운영에서 절대 그럴일 없다고 하는 말은 그냥 믿지말것. 이 정도는 정말 지켜주지 않을까? 라는 것도 사치임 변해서 안쓰게된건 꼭 feature 로 잡아서 업무시간으로 활용하여 꼭 진행할것.코드, 테이블을 지우는 사람을 대접을 못 받지만, 나중에 편하다. 사용하지 않는 API 감지하고 싶으면 AOP 로 만들어서 알람을 받는식으로 하면 참 편했던거같다. 내가 요청하긴 했지만 팀 동료가 잘 만들어놔서 잘 썼다. 재미로 회사를 다니긴했지만 좀 더 의식적으로 부드러운 커뮤니케이션을 해볼까. 이젠 어른이니깐 단호함과 예의없음을 잘 구분하자만난 직후보다 떠날때의 뒷모습이 더 중요하다. 남은 사람들에게 성의를 보이자. 사람은 헤어질 때 진짜 모습이 나타난다." }, { "title": "Opensearch 가이드 용 문서", "url": "/posts/opensearch-%EA%B0%80%EC%9D%B4%EB%93%9C/", "categories": "Blogging, Database", "tags": "database, elasticsearch, sharding, opensearch", "date": "2025-10-30 03:00:00 +0000", "snippet": " 분산형 검색 및 분석 엔진 Elasticsearch 오픈소스 기반으로 Amazon이 유지 중인 Community-Driven Fork 분산 인덱싱 + 검색 엔진 → 대용량 로그, 메트릭, 문서 데이터를 수평 확장으로 처리 REST API 기반으로 쉽게 접근 (/_search, /_cat/indices 등) 인덱스(Index)와 샤드(Shard) 구조 인덱스 = 데이터베이스의 테이블 개념 샤드 = 인덱스의 물리적 분할 단위 (기본 Primary + Replica 구성) 노드 단위로 자동 분산 저장되어 장애 대응 및 부하 분산 가능 _cat/shards 명령으로 샤드 상태 확인 가능 인프라 구성 master(대장), coordinate(트래픽받는애), data node(데이터 저장 노드) nginx 외부망 열린 -&gt; k8s ingress helm -&gt; dashboard pod 인덱스 관리 (dashboard 에서) index management policy template alias Alerting (알림 기능) 조건 기반 트리거 설정 가능 (CPU &gt; 80%, 에러로그 100건 이상 등) Slack, Email, Webhook 등으로 통보 가능 같이 보면 좋은 정리" }, { "title": "요즘 우아한 개발", "url": "/posts/%EC%9A%94%EC%A6%98-%EC%9A%B0%EC%95%84%ED%95%9C-%EA%B0%9C%EB%B0%9C/", "categories": "Blogging, Book", "tags": "culture", "date": "2025-05-10 09:00:00 +0000", "snippet": "온보딩 요구사항 분석 -&gt; 설계 -&gt; 문서화 -&gt; 임무 분담 -&gt; 개발 -&gt; 배포 -&gt; 회고 를 그대로 경험하게 하자.개발문화 공유에 대한 심리적 문턱이 낮은문화 우리회사는 글 쓰는데 검증하고, 허락받고 전혀 하고싶지않은 구조로 몰고감 ㅋㅋ 페어 프로그래밍 강추 피트스탑 제도 기술부채 터는 2주일 ~ 4주일 회고 Keep Problem Try 2주단위는 어때마음편한 질문 분위기 반복되는 질문에 신경질적인 반응을 가장 경계하자잡담이 경쟁력이다." }, { "title": "slack 봇 만들며 깨달은 후기", "url": "/posts/slack-%EB%B4%87-%EB%A7%8C%EB%93%A4%EB%A9%B0-%EA%B9%A8%EB%8B%AC%EC%9D%80-%ED%9B%84%EA%B8%B0/", "categories": "Blogging", "tags": "slack, nextjs", "date": "2024-12-25 09:00:00 +0000", "snippet": " nextjs 는 신이다. 자바따위랑 비교가 안되는 고속 애플리케이션 개발 가능. 근데 회사에서 deploy 하는게 너무 힘들다. npm build, docker from 전부다 프록시태워야해서 개 혈압오름. typescript 는 진짜로 그 production level application 만들때나 쓰자 개인 프로젝트 하다보면 가볍게 만드는데, 인터페이스 선언하는게 너무 오래걸림. 뭐 그라파나 api 호출하면 response 모델만드는게 지옥같음. 코드만 더럽게 차지하고 정작 로직은 잘 안 보임. 그러다보니 any 처리하거나, lint 에 잡히는데 매번 욕 나옴. slack block builder 는 gpt 가 너무 저퀄리티로 만들어줘서 그냥 내가 직접 만드는게 나음. 그리고 slack block builder 는 뭔가 예쁜 UI 는 잘 안나옴. (텍스트, 버튼, 이미지 적절한 조합이라던가… 그런건 안됨.) 정말 심플한 봇이어야함. 무엇보다 기획자의 소중함을 알았다. 개발먼저 시작하지말고 기획을 잘하고, 개발스타트를 해야 비용이 오히려 안듦… 나중에 UI 추가하려니 넘 꼬인다." }, { "title": "Next.js 내가 몰랐던거만 정리한 요약 (실전에서 바로 쓰는 Next.js)", "url": "/posts/%EC%8B%A4%EC%A0%84%EC%97%90%EC%84%9C-%EB%B0%94%EB%A1%9C-%EC%93%B0%EB%8A%94-Next.js/", "categories": "Blogging, Book", "tags": "nodejs, nextjs, react", "date": "2024-12-24 09:00:00 +0000", "snippet": "책 정보 실전에서 바로 쓰는 Next.js 미셸 리바 yes24큰 특징 요약 정적 사이트, 증분 정적 컨텐츠 생성 파일 기반 라우팅 이미지 최적화 자동폴리필 리액트잡다한 팁 npx create-next-app my-app --example with-docker 디렉토리 pages : 가장 중요. 퍼블릭 페이지들 public : 정적 컨텐츠, 퍼블릭 페이지, 컴파일된 js styles : 스타일시트. 필요없음 바벨 웹펙 커스터마이징 하려면 next.config.js 에 하는데 하지마렌더링 전략 하이드레이션 : 렌더링한 페이지에 스크립트 집어넣어서 나중에 동적으로 처리하는 개념. 맨날 쓰는건데 그럴듯한 용어 CSR : 그냥 기본 쉬운 페이지 전환 서버 부하감소 지연된 로딩과 성능. css js 벌크 받다 느리면, seo 낮은 점수 SSR : getServerSideProps 예약어임. SSR 이 더 서버 고비용이다. 대신 SEO 에 좋은 점수 SSG : 정적 사이트 생성. getStaticProps ISR : 증분 정적 재생성 기능. 어느 정도의 주기로 정적 페이지 랜더링 가능함. getStaticProps 안에서 return 에 revalidate 속성 주면됨. 실무 jest 테스트 코드 통합테스트는 뭐 소개해주는게 그냥 유닛테스트나 잘짜자. utils 위주 아토믹 디자인 원칙 근데 쓰다보면 이게 분자인지 유기체인지 가끔 햇갈림. 비즈니스 로직은 유기체에 두고, 분자와 원자의 재사용성을 높이자. 상태관리 context API 차라리 순정이라 깔끔 redux 보일러플레이트 코드 너무많아서 짜증 recoil 낫베드 스타일 : scss 쓰자. custom 서버가능함. but vercel 배포안됨. 필요하면 express 맨 앞단에 리버스프록시처럼 쓸 수 이씀. 인증은 필요하면 Auth0 플랫폼 이용하자" }, { "title": "비 그친 오후의 헌책방 1,2", "url": "/posts/%EB%B9%84-%EA%B7%B8%EC%B9%9C-%EC%98%A4%ED%9B%84%EC%9D%98-%ED%97%8C%EC%B1%85%EB%B0%A9/", "categories": "Blogging, Book", "tags": "novel", "date": "2024-12-24 09:00:00 +0000", "snippet": "책 정보 비 그친 오후의 헌책방 야기사와 사토시 yes24 잔잔하다 독서의 묘미를 다시 알려주는 책 가족애 비오는 날 습한, 골동품 냄새나는 책" }, { "title": "Kafka 맨날 까먹는거만 정리", "url": "/posts/Kafka-%EB%AA%B0%EB%9E%90%EB%8D%98%EA%B1%B0/", "categories": "Blogging, Architecture", "tags": "kafka, queue, async", "date": "2024-12-16 09:00:00 +0000", "snippet": "그냥 줄글로 다 남긴다 log.retention.ms , log.retention.byte 토픽당 설정한만큼 record 들이 살아남음 브로커 복제 ISR 카프카는 보통 브로커 3대를 권장함 partition 1, replication 2개면 원본 1개와 복제본 2. broker 보단 크게 설정 못함 leader partition(진짜), follower partition(복제) = ISR In Sync Replication 구조 ack 는 replication 과 관련이 있고, 0(던지고 뒤돌아섬), 1(던지고 응답은받음), all(replication 까지 완료) 얼마나 replication 전파시킬지 결정 파티셔너 프로듀서에서 토픽에 어떤 파티션에 넣을지 결정하는 애, record message key가 hash 값으로. 파티션도 나누며, 내가 의도한 곳에서 순서를 지킬수가 있음. vip 고객은 빠르게 하고 싶다면 나눌 수 있을듯. 컨슈머 컨슈머 랙 offset - 앞에서부터 들어있는 숫자 인덱스값 프로듀서가 넣은 offset - 컨슈머가 가져간 offset = 컨슈머 lag 파티션 2개 일때, lag 이 2개가 존재함. 컨슈머는 partition 갯수보다 적거나 같아야 효율적 컨슈머 그룹 이 중요해. offset 서로 나눠서 저장함. 카프카 스트림즈 : Stateful 한 애플리케이션의 복잡한 상태관리 카프카 커넥트 : 데이터 파이프라인용" }, { "title": "MAC 새로받고 해야하는 짓 모음", "url": "/posts/MAC-%EC%83%88%EB%A1%9C%EB%B0%9B%EA%B3%A0-%ED%95%B4%EC%95%BC%ED%95%98%EB%8A%94-%EC%A7%93-%EB%AA%A8%EC%9D%8C/", "categories": "etc", "tags": "개발환경", "date": "2024-12-09 03:00:00 +0000", "snippet": " spotlight, 입력소스 변경 마우스 트랙패드 자연스러운 스크롤, chrome 메인 구글 로그인 brew 설치 docker desktop nodejs appstore 로그인 적당히 클릭질 JetBrain tool - intellij, pycharm, datagrip 체크아웃 https://github.com/OsoriAndOmori/OsoriAndOmori.github.io git config –local user.email xx git config –local user.name xx slack warp notion kube ssh config 복붙. 슬랙에 개인 메세지함에 있음 openlens 회사 vpn, 회사망, 인증 필요한 repo checkout : api, 문서함" }, { "title": "저속노화 식사법", "url": "/posts/%EC%A0%80%EC%86%8D%EB%85%B8%ED%99%94%EC%8B%9D%EC%82%AC%EB%B2%95/", "categories": "Blogging, Book", "tags": "건강", "date": "2024-09-30 09:00:00 +0000", "snippet": "책 정보 저속노화 식사법 정희원 yes24인슐린 분비 = 노화술은 뇌의 독 항산화 효과는 있을지도 모르지만 연구가 똑바로 되지않음 (대조군 변인통제 실수 등)추천음식 렌틸콩 그릭요거트 블루베리 올리브오일 생선 잡곡밥 6:4 베스트는 8:2 두부, 아몬드, 분리대두단백 식물성 단백질이 1티어 적색 육류는 가금류 고기보다 구림 생선 &gt; 닭 &gt; 적색육류 푸른잎 채소 : 시금치, 케일, 상추, 쌈채소빌런모음 흰쌀밥, 빵, 쿠키, 떡 정제곡물중요키워드 인슐링 저항성 : 정상적인 인슐린의 작용에 대해 세포가 반응하지 않는 상태 코르티솔 : ET 체형 만들기. 스트레스 받으면 영양소 저장을 위한 매커니즘 식욕을 결정하는 다양한 요인들 : 배고픔, 혈당, 스트레스 등. 그 중추는 “혈당”인지해야할 이미지 중요한 느린 혈당 증가" }, { "title": "스프링 부트와 AWS로 혼자 구현하는 웹 서비스", "url": "/posts/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8%EC%99%80-AWS%EB%A1%9C-%ED%98%BC%EC%9E%90-%EA%B5%AC%ED%98%84%ED%95%98%EB%8A%94-%EC%9B%B9-%EC%84%9C%EB%B9%84%EC%8A%A4/", "categories": "Blogging, Book", "tags": "nodejs", "date": "2024-09-27 09:00:00 +0000", "snippet": "책 정보 스프링 부트와 AWS로 혼자 구현하는 웹 서비스 이동욱 yes24독후감 부트 내용은 다 건넜고, 필요한 것만 정리함. aws 의 경우 k8s 내용은 없고 단순 ec2 와 db 생성, 그리고 shell script 를 통한 수동 무중단 배포라 주니어 때 보기 좋은 듯.AWS 이용한 무중단 CI / CD travis, aws s3, code deploy aws s3 를 이런식으로 활용하는 듯. 대충 머리에 인덱싱만 해놓자 Travis 대체 할 만한 것 Jenkins : 설치해야해서 돈나감 TeamCity : 젯브레인에서 만들고있음. Nginx 를 통한 블루그린 deploy 하나는 8081, 하나는 8082 포트로 띄우고 미리 준비된 nginx 설정파일 2벌로 교체를 해줌. proxy pass 부분만 8081, 8082 왔다갔다~ 상황에 따라 spring property 도 real 두벌로 가기도 하는듯." }, { "title": "내 맘대로 팀 입사 교육과정", "url": "/posts/%EB%82%B4-%EB%A7%98%EB%8C%80%EB%A1%9C-%ED%8C%80-%EC%9E%85%EC%82%AC-%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95/", "categories": "Blogging, Spring, Tutorial", "tags": "spring", "date": "2024-03-24 09:00:00 +0000", "snippet": "규칙 실습 Repo : https://github.com/OsoriAndOmori/developer-guide-spring 실습생은 자기 새로운 repo 를 파고 시작 Java 건 kotlin 이건 알아서 팀원들에게 주기적으로 배운 내용 공유 &amp; 피드백 받기 하면서 가이드 외 학습 추가 (security, webflux, kotlin 등등) 네트워크 HTTP HTTPS HTTP 1.1 주요 Header 들 고급) HTTP 2.0, HTTP 3.0 TCP/IP 고급) UDP 란? Spring Framework Servlet apache-tomcat 다운 받기 jakarta.servlet-api dependency 하나만 추가후, tomcat 에 띄워서 hello 응답받아보기 spring-framework-mvc, war 로 빌드 후 띄워보기 embeded-tomcat dependency 추가후, 직접 수동으로 Spring Container 만들어서 Embeded tomcat + dispatcher Servlet 붙여보기 Spring-Boot boot 로 전환해보기 spring 에서 autoconfigure 을 어떻게 해주는지 파악해보기 (사용법 말고, 어떻게 auto configuration 들을 코드상에서 찾아서 넣는지) importSelector 유용한 기능 autoconfigure 해주는 starter 하나 직접 만들기 gitlab repo 에 jar 업로드하고, repo 로 추가하여 다른 프로젝트에서 다운 받아보기 Spring 학습 이후 다시 생각해보기 spring bean 에 관한 기본적인 내용들 싱글톤 Spring container : 구글링 해서 할 수 있는 곳 까지 직접 구현해보자 : 샘플 객체지향과 Spring 스프링은 왜 만들어졌을까 객체지향 : 역할 책임 협력 역할 책임 협력을 하게되면 의존성을 서로 가지게 된다. 인터페이스는 귀찮기만하고 뭐하는걸까 대체 SOLID 의존성 주입(DI)과 의존성 역전(DI)에 관한 심도있는… 객체지향의 대표적인 안티패턴 순환참조 - 레이어드 아키텍쳐와 스프링 양방향 레이어드 아키텍쳐 스마트UI 아키텍쳐 - 스프링의 특징 DI IoC AOP PSA 강의 노트```- 지난시간 요약 - SOLID - 의존성 주입, 의존성 역전 - InterfaceTestConfigTest.java - 한 줄 요약 하자면 : 인터페이스를 잘 써서 의존성을 '약화' 시키고, 클래스를 많이 쪼개는 버릇을 들이자 - UserSerive 이딴거 금지. 오늘 만들고왔으면 가서 네이밍 변경하던가, 더 쪼갤것- 샘플 코드를 먼저 좀 보자 - TeamTest.java - ApplicationWebMvcApplication.java- 순환 참조 좀 있으면 안되냐? -&gt; 안됨 - 예상하지못하는 에러 발생 - 시스템 복잡도를 높임 - 무조건 재설계하자- 레이어드 아키텍쳐 - controller, service, repository - 구분해놨는데, 다른프레임워크도 보통 이래.. nextjs 보고오자 - 완전 내 의견으로 c,s,r 의 레이어구분 : 완전 비판적으로 받아들이세요. - c 최대 3줄 - application service 비즈니스로직인데, 남은 비즈니스로직을 실행만 딱딱 시켜주는애 , domain service - r 은 persistent layer- 내가 생각하는 webflux 기준 레이어드 아키텍쳐- smart ui 디자인패턴이 되지말자 - 트랜잭션 스크립트- 요약 - 레이어드 아키텍쳐를 기억하자 - 설계후 개발하는걸 습관해보자 interface 적극 활용 너무 활용했을때 복잡도 높이면 어떡해? 코드 퀄리티 망하는것도 경험해봐야해. - 스프링 core 자체 부트캠프는 여기까지, 이후 공부 추천하는 방법 : 인프런에서 마구마구 사며 반복 학습, 빠르게 스킵하고 알짜만 계속 주워먹는다.``` Spring Batch 그냥 배치돌리는 API 를 jenkins 로 호출해버리면 안됨? chunk oriented 개념 그럼 언제 써야할까 간단한 스프링 배치 구조와 사용법 고급) 싱글쓰레드 배치, 멀티쓰레드 배치 synchronized 초 대용량 배치는 어떻게 하면 좋을까. 유저 데이터 억건 이런거 DB 데이터 설계 : 한 테이블에 다 때려넣기 vs 교과서대로 테이블 분리 장단점 생각해보기 (정규화와 역정규화) 정규화 isolation, propagation 실습 Spring AOP 와 트랜잭션 spring 없을때 트랜잭션 코드 살펴보기 ProxyTransactionManagementConfiguration, TransactionInterceptor, TransactionManager 테이블, 컬렉션 index 는 어떻게 설정해야 할까 cardinality 와 b+트리 강의노트```- propagation - REQUIRED - 트랜잭션이 필요해, 생성 + 만나면 기존거에 참여 - REQUIRED_NEW - 새 트랜잭션이기 때문에, 커넥션 고갈야기 할 수도잇음- index - index : '정렬'이 되어있어야함 + 그리고 실제 data disk 주소를 들고있어야함. - 정렬하면 list 로만 될까? - 왜 hashMap 을 안썼을까 O(1) 인데 -&gt; 시간남으면 hashMap ? hash``` 캐시와 타임아웃 글로벌 캐시와 로컬 캐시 스프링 로컬캐시 caffeine, ehcache 글로벌 캐시 redis, nginx, varnish 등 각 네트워크 단계마다 다양한 타임아웃 설정들 db api webserver 클라이언트에서 서버까지 뒤로 갈 수록 타임아웃은 어떻게 해야할까 Web / Proxy 프록시, 리버스 프록시 개념. 웹서버 (nginx 등) vs 웹어플리케이션 서버 웹 어플리케이션과 웹서버 같이 썼을 때 해주면 좋은 것들, 로컬에서 한번 붙여보세요 우리팀은 보통 어떻게 쓰는가 화면 렌더링 : SSR CSR SEO 풀스택 개발자가 되기위한 첫걸음? 서블릿 프로그래밍 떄부터 이전 화면 렌더링 전략들 대세 thymleaf 와 react SSR, CSR 의 장점과 단점 개발자의 부족한 디자인 감성으로 화면 만들때 도와주는 도구들 Code Deploy 여러대에 배포를 하려면 어떤 전략이 있을까 rolling, blue/green, canary LoadBalancer, Health check 좀 더 복잡한 구조일 때 효율적인 배포한번 봐보기 ansible 사용법 : 남이 작성한 것 플로우 따라가보기 실제 2대 서버로 무중단으로 배포해보기 마음대로 조작해보자 시간남으면 k8s 배포해볼까 로깅 spring application 로그 설정 docker compose 를 활용해 elasticsearch 에 로그 넣기 fluentbit -&gt; fluentd -&gt; elasticsearch 관계 알기 좀 다르게 loki 쓰고 grafana 로 보기 slack 알람까지 연동 모니터링 실습 repo 이용하여 grafana, micrometer, prometheus 연동하고 각각 뭔지 파악하기 dashboard import 해보기 일부러 dbcp 소진하고 모니터링 해보기 jvm heap 메모리 전부 소비하고 모니터링 해보기 수집 주기 관련 중요한 내용 우리서비스에서 어떻게 적용되어있는지 확인 tracing pinpoint jvm heap dump 분석 테스트 TDD 란? TDD 까지 해야하는가? 시연 Mocking 에 관하여 테스트코드를 많이 짜기만한다고 되나 given, when(stub), then, assert, verify 가 한 화면에 테스트 데이터 generate 하는 부분은 별도 class 로 빼자 fixture-monkey 적극 이용하자 자기 repo에 테스트 Coverage 기능 추가해보기 아키텍쳐 설계해보기 자기가 네이버 메인 개발자라면 설계해보기 각자 할겁니다. 자기 노트북 스케치북이건, 노트건, drawio 건 깔아오세요 DB, Cache 뭐 카프카 이런거 알아서~ 정해요. 어드민도 필요하면 어드민도 만들어야함. 아래같은 그림을 만드는 느낌으로 필요한 서버 대수도 한번 가늠해보셈 성능 테스트 많이 쓰이는 성능테스트 툴들 ngrinder locust k6 우리팀 성능테스트 테스트 관련 숫자들 vuser (active user) : 충분한 트래픽을 집어넣어야함. 점점 올려서 duration : 최소 2~3분? 짧게 실행하면 모르는 혹시나 모르는 메모리릭 같은거 확인 ramp up : 경험상 별로 상관없는듯. 한방에 막 집어넣으면 초기 TPS 가 떨어지긴함. 코딩 스킬 &amp; 습관 좋은 코드 쓰는 법 함수형 특징을 머리의 새기자 불변성 순수함수 - 부수효과 X (Exception 던지고 받고 하지 마세요) 비전문가에게 설명하는 코드 매일 15분 정도 표준 라이브러리, spring 코드 뒤져보기 미학적으로 보기 좋은 코드가 좋은 코드 리팩토링 연습 팀 내 마음에 안드는 코드 같은게 있으면 리팩토링 해보자 리팩토링할 메서드 전에 테스트코드 감싸기 코드를 아름답게 짜는 방법은? (필수) 읽기 좋은 코드가 좋은 코드다 (선택) 리팩토링 고급) 함수형 프로그래밍이란? 저도 아직 잘 모르겠음. 디자인 패턴 : https://refactoring.guru/ko 팩토리 프록시 커맨드 개인적인 공부방법 코딩 스타일과 팀 생활 동료와 개발 의견이 다를땐 어떻게 해야하나.. 저도 아직 잘 모르겠음. 코딩 스타일의 차이가 있을 때 설계 차이가 있을 때 모르는건 동료 개발자에게 바로 물어봐야할까? 계몽 vs 전염 뭐가 더 좋은지 의미 생각해보기 성장한다는건 뭘 하는걸까 새로운것을 배움? 과거의 잔재를 버림? 개발자의 역할은 뭘까 요구되는 비즈니스 구현이 먼저냐 vs 기술부채 해결하여 안정적이고 우아한 시스템 구현이 먼저냐 예쁜 문서화가 업무에 영향을 미치는 것 맨날 변하는 스펙 문서화하는게 시간이 너무 걸리는데 어떡하지? 더 알아보면 유용할 주제 Docker mysql 직접 다운받아서 어플리케이션으로 로컬에서 띄워보자 원하는거 daemon 위에 띄워주는거라고 생각하고 mysql 띄우고, database IDE 를 이용해서 접근 자기 repo 내 docker-compose.yml 로 띄워보기 어플리케이션 만든거 docker image 로 만들어서 개인 docker hub push 해보자. Webflux Kotlin Kubernetes Front End" }, { "title": "Spring boot 핵심 원리", "url": "/posts/%EC%9D%B8%ED%94%84%EB%9F%B0-%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8-%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC/", "categories": "Blogging, Spring", "tags": "spring", "date": "2024-03-20 09:00:00 +0000", "snippet": " 이 게시물은 김영한 - 스프링 부트 핵심 원리 요약임 모든 코드는 OsoriAndOmori/playground-spring 에 올려둠. 멋대로 만든 프로젝트 구조 이기 떄문에, 강좌 내용은 따라가나 구조는 절대 따라가지 않음..웹 어플리케이션 컨테이너 (톰캣 직접 사용 &amp; servlet 개발) spring boot 빼고 이거 한번 구현해봄. Servlet 컨테이너 초기화 -&gt; 어플리케이션 초기화(Servlet 등록) 여기서 어플리케이션 초기화 과정에! spring container 만들면 되는거임. DispatcherServlet 은 controller 를 호출해주는 servlet 하나의 서버에 DispatcherServlet 도 두개만들고, spring container 도 여러개 띄울 수 있음. 근데 보통 이렇게 안하지 ㅋㅋ spring 에서 WebApplicationInitializer 가 어떻게 어플리케이션 초기화 할때 하는지 이해해야함. 결국 위에서 META-INF 등록하고, @HandleType 써서 쫙 class 가져와가지고 init 하는건 똑같음. 여기까진 서블릿 컨테이너 위에서 모든걸 개발한 것임 빌드 배포 jar 는 다른 jar 를 품지 못함. 하지만 클래스는 다 가질 수 있다. 그래서 library 에 있는 class 를 꺼내서 집어넣음. -&gt; fat jar 로 만든다. fat jar 는 이름 겹치는 문제가 발생해서 실행가능 Jar 를 만듬 실행가능 Jar = bootJar 명령어를 통해서 만들고 bootJar 는 플러그인이 만듦 WebApplicationInitializer 인터페이스 이용해서 spring container 만들고, tomcat 만들고, dispatcher servlet 등록하고 띄움 TomcatWebServerFactory 브레이크 걸고 봐. Spring boot 내가 주시해야할 패키지 spring-boot autoconfigure : 코드 spring-boot-starter : https://github.com/spring-projects/spring-boot/tree/main/spring-boot-project/spring-boot build.gradle 만 있고 parent pom 같은거라고 생각하면 됨. 실행 가능 jar 란? JarLauncher.class main 을 보면됨 스프링 컨테이너 만드는 곳 : org.springframework.boot.web.servlet.context.ServletWebServerApplicationContextFactory 내장 톰캣 만드는 곳 : org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory Autoconfiguration 기능 Condition 인터페이스를 구현해서 META-INF/spring/*AutoConfiguration.imports 에다가 넣음. autoconfigure 잘 뒤져서 보면 됨. @Import(AutoConfigurationImportSelector.class) ImportSelector 로 동적으로 등록할 수 있음을 인지. @Conditional - @ConditionalOnProperty, @ConditionalOnClass, @ConditionalOnBean, @ConditionalOnXXXXX 모니터링 micrometer 라는 거로 cpu, mem 측정 추상화를 다 시켜버림 이후 그 데이터로, 프로메테우스보내던가 JMX 로 보내던가 구현체만 따로따로 만들면 됨. 다양한 메트릭은 /actuator/metrics리스트보고 /actuator/metrics/{metricname} 하면 하나하나 볼 수 있음. /request 보면 max time, 이런거 다 기록되어있음 -&gt; 이걸 그대로 prometeous 로 날리는거임. tag=level:error 이런 기능도 가능. 사용자 정의 메트릭도 가능 - 주문 숫자 뭐 이런거로 서버 숨졋나 확인 가능. 마이크로미터 &lt;-주기적떙겨감– 프로메테우스 &lt;-PromQL- 그라파나 프로메테우스만으로도 그냥 데이터 볼 수 있지만, 공유 dashboard 를 적극 활용하자 MeterRegistry micrometer 활용해서 커스텀한 수치를 prometheus 를 추가할 수 있음 : AOP (@Counted, @Timer, @Timed)" }, { "title": "모든 개발자를 위한 HTTP 웹 기본 지식", "url": "/posts/%EB%AA%A8%EB%93%A0-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-HTTP-%EC%9B%B9-%EA%B8%B0%EB%B3%B8-%EC%A7%80%EC%8B%9D/", "categories": "Blogging, Http", "tags": "브랜딩", "date": "2024-03-13 03:00:00 +0000", "snippet": "참고 강의 모든 개발자를 위한 HTTP 웹 기본 지식인터넷 네트워크 ip 는 그냥 위치정보만 알려줌. 그래서 이것만으로는 너무 부실함 tcp 는 전송방식, 순서, 검증 이런거 하게해줌. tcp / ip 꼴라보로 신뢰성있는 통신을 할 수 있게됨 3 way handshake (sync / sync ack / ack) udp 는 그냥 ip 위에다가 포트정보만 추가해서 빈 도화지에서 자유롭게 데이터 주고받기 -&gt; 빠름 이미지나 동영상보낼떄 udp 쓰라고 그랬었는데, tcp 가 점유율 90% 넘어갔다가 http 3.0 나오면서 다시 주목받고있는 중 웹브라우저 uri = url + urn : urn 은 걍 무시하자 url 치면 http 로 변경 -&gt; tcp / ip 랩핑 -&gt; 보냄http http 2,3 은 성능개선에 초점. 1.1 이 사실상 가장 중요한 버전 특징 클라이언트 서버 구조 무상태 프로토콜, 상태 유지가되면, 중간에 다른 서버로 바뀌면 안된다. 중간에 서버가 바뀌어도됨. 서버를 여러개 투입해서 서빙하는 이미지를 생각해. 모든걸 무상태로는 못함. 로그인 같은건 어떻게 해결할까? 브라우저 쿠키 Session?, 데이터를 많이 보내는 단점도 있음. 비연결성 3 way handshake 하는 시간이 매번 추가됨 keep-alive(persistent connection) 으로 성능 개선함. 그럼 비연결성 이라고 장점이라고 쓰면 될까..? 메세지를 통해 주고 받음 GET / POST 사실 POST 로 모든걸 다 할 수 있어보이지만, 조회는 GET 쓰는게 좋음. Caching 떄문 메서드 속성 안전 : 변경하는거면 안전하지않은거임… 멱등 : 몇번요청하든 결과가 똑같다. POST 는 아님! 결제 여러번할수도잇음. (중간에 데이터 변경되는것 까진 고려하지않음) 캐싱 401 Unauthorized 인증이 되지않은거임 401발생하면 WWW-Authenticate 에 헤더와함께 인증방법 설명해야함. 사실은 UnAuthenticated 가 되어야할거 같은데 이름이 너무 아쉽다. 402 Forbidden 진짜 Unauthorized 인 경우. 인가가 안되어있는 경우. http 헤더 표현(Representation) 이라고 하는 이유는 결국 특정 정보가 json 이건 html 이건 결국 ‘표현’ 되기 떄문 표현 헤더는 전송, 응답에 둘다 사용함. Content-Length, Encoding, Language 협상(Accept) Header : 요청시에만 사용함. ‘클라가 선호’하는걸 서버에 보낼 때 씀. Accept: 클라가 선호하는 미디어 타입 Accept-Language: ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7 1부터 우선순위, 생략하면 1 협상 우선순위 구체적일수록 우선순위가 높다. 전송 분할 전송 : Transfer-Encoding: chunk 서버가 일부분씩 짤라서 보내는거 범위 전송 일반 정보 Referer: 어디서 들어왔는지 볼 , User-Agent Retry-after 라는것도 있음. 인증 Authorization: 클라이언트에서 서버에 인증 정보 전달함. WWW-Authenticate: 뭔 정보 참고해서 똑바로 인증만들고와 Cookie 서버가 쿠키 줄 떈 Set-Cookie 응답에 포함되어있음. Set-Cookie: user=홍길동 expire, path, domain 들로 제약을 해둠. Cookie 는 클라가 서버로 올릴때 사용. Secure(https 에서만), HttpOnly(js 접근금지) 캐시 cache-control 로 제어함 근데 캐시만료되었을때 서버가 데이터 안변경했으면 굳이 또 받을필요가? 검증헤더 활용함. Last-Modified(응답할떄), if-modified-since(보낼때) -&gt; 304 Not Modified 받으면 재활용함. 근데 1초미만 캐시 조정이 불가능해서 날짜기반은 아무래도 정확하지 않음. ETag,if-none-match 라는걸 활용하는 검증 방법도 있음. 해당 리소스의 hash key라고 생각하면 됨. pragma, expire 는 하위호환 떄문임, 걍 버리고 cache-control 만 알고있자. 캐시지시어 cache-control: max-age cache-control: no-cache = 캐시해도되긴하는데, 항상 원서버 가서 검증하고 써라 cache-control: no-store Proxy-cache (CDN) cache-control: private, public(proxy 에 저장해도 됨), s-maxage(프록시캐시서버 저장시) Age: origin 서버에서 응답후 프록시 캐시내 머문 시간. must-revalidate : 혹시나 proxy cache 에서 origin 서버가는길에 네트워크가 단절되었을때 proxy-cache 서버가 멋대로 가라응답 주는거 방지하고 에러코드 뱉도록 정의함. " }, { "title": "Flutter 초입문 왕초보편 (요약)", "url": "/posts/Flutter-%EC%B4%88%EC%9E%85%EB%AC%B8-%EC%99%95%EC%B4%88%EB%B3%B4%ED%8E%B8/", "categories": "Blogging, Flutter", "tags": "flutter, iOS, Android", "date": "2024-03-11 08:00:00 +0000", "snippet": " 이 게시물은 오준석 - Flutter 초입문 왕초보편 요약임 모든 코드는 OsoriAndOmori/LoveSj 에 올려둠. 멋대로 만든 프로젝트 구조 이기 떄문에, 강좌 내용은 따라가나 구조는 절대 따라가지 않음..듣고보니 객체지향은 최소한 알고 들어야하고, 개발 할 줄 모르는 사람이 들으면 아무리 왕초보여도 어려울듯? ㅋㅋ기본 대충 살펴보니 dart 는 js, kotlin 짬뽕이고, flutter 앱 자체는 상태관리로 리액트 개발해봤으면 아주 쉬워보임 ㅋㅋ Scaffold - 화면, appBar - 상단 앱바 pub.dev 에서 라이브러리 임포트 한 화면당 파일하나 구분해주는게 일반적인것 같음. 기본이 material-ui 컨셉이고, 레이아웃은 Row, Column, ScrollView 이용해서 적절히 배치하면 됨 화면 갱신하려면 메서드 마지막에 setState(() {}) 호출비만도 계산 임시 저장소. 라이브 템플릿고 nav push 활용해서 네비게이션 Shared-Preference사용하면 됨스톱워치 async 패키지에 들어있는 Timer와 Duration 으로 개발WebView 사용시 WillPopScope 로 뒤로가기 제어 가능이미지 관리 ImagePicker 사용하자 FutureBuilder 라는거 써서 비동기로 받는거 동기처럼 개발할 수 있게 지원 가능. PageView - children 써서 로 좌우 스와이프 가능하게 할 수 있음.수평측정기 package sensor_plus 간단하게 몇가지 센서 활용하게 함. SteamBuilder + eventController 집어넣어서 정보 받아 올 수 있음.실로폰 soundpool 활용해지도앱 google map flutter 패키지 내 샘플코드 넣고 시작하자. geolocator 사전에 해야하는 것들 같은건 pub.dev 보면서 잘 해야함. 그냥 위치조작과 async / await 잘 써서 카메라 위치 이동시키고 하면 됨. 샘플 잘 주작하면 되는느낌.TODO 리스트 Hive 라이브러리써서 로컬 db 활용 가능함. repository 열고 닫고를 잘해야할거같은데 이건 좀 개발해본사람한테 물어봐야할듯. 여기선 안나오네만들 앱 LoveSJ 플러터버전 과 알람 + Dday 설정할 수 있도록 1주일, 3일 전에 앱 푸시해줌. 안드 퍼블리싱까지 가족 위치앱 공유용" }, { "title": "우피와 노션으로 웹사이트 만들기", "url": "/posts/%EC%9A%B0%ED%94%BC%EC%99%80-%EB%85%B8%EC%85%98%EC%9C%BC%EB%A1%9C-%EC%9B%B9%EC%82%AC%EC%9D%B4%ED%8A%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0/", "categories": "Blogging, Branding", "tags": "브랜딩", "date": "2024-01-07 09:00:00 +0000", "snippet": "참고 강의 인프런 - 코드없이 우피x노션으로 초간단 웹사이트 만들기조합 우피 : 퍼블리싱 (보다 웹 공유 최적화) https://www.oopy.io/ 여기에 댓글 정책, 구글 ana search console disqus 로 댓글 적용 노션 : 문서 작성" }, { "title": "함께 자라기", "url": "/posts/%ED%95%A8%EA%BB%98%EC%9E%90%EB%9D%BC%EA%B8%B0/", "categories": "Blogging, Book", "tags": "애자일", "date": "2023-12-13 09:00:00 +0000", "snippet": "책 정보 함께 자라기 김창준 yes24 자라기 (학습) 연차는 저연차일수록 차이가 나고 5년차부턴 차이가 없다. 야생학습 개념 개발 잘 하는 사람은 문제를 이해하는데 시간을 덜 씀. 분석이 더 중요함. 연차는 최소 기준만 넘기면 상관관계가 낮다. 다양한 경험이 더 상관관계가 있다. 일의 정의, A : 그냥 일. B : A를 개선하는 일, C : B를 더 잘하기위해 하는 일. 소프트웨어 개발자는 미래 인공지능이 대체하기 어려운 직업군으로 분류되는 편임 암묵적이고, 애매한 것이 많을수록 인공지능의 영역에서 멀어짐. 창의적으로 일을 만들어내는걸 중요하게 여김. 달인의 비결. 동기와 빠른 피드백 튜토리얼 할때 : 적극적 읽기 - 뭔가 만들어야함. 만들만해지면 멈추고 만들어봐 실수 예방하려고 하지말고, 실수 관리에 더 중점을 두자. 더 빠른 장애 감지를 위한 연구? 예방하려다보면 실수 한사람을 비난할 확률이 높음. 관리에 중점을 두는 문화면 비난할일 없음. 실수를 해야 배운다. 하지말라고하는건 배우지말라는것과 동일 어떤 기술적으로 훌륭한거여도 현실에 적용하기위해선 사회적 자본(=신뢰같은거)과 기술이 필요하다. 전문가라 함음 사회적 기술도 뛰어나다. 뛰어난 기술자는 타인과 인터렉션에 더 시간을 쓴다. 중요한 사회적기술 리스트 : 도움받기, 피드백 주고받기, 영향력 미치기, 가르치고 배우기, 위임하기 함께 (협력) 소프트웨어 품질에 영향을 주는 순서는 관리, 시스템, 사람, 도구 순서인데 실제 관리자는 도구부터 개선하려고함. 공유 : 하나공유, 최고공유는 신뢰도를 떨어뜨림. 복수공유 만이 신뢰를 올릴 수 있음. 복수개의 아이디어를 프로토 타이핑 하고 공유하자. 기업이 탑다운이라고해서 팀이 탑다운일 필요는 없다. 소프트웨어 개발은 항상 전략 -&gt; 범위지정 -&gt; 구조 셋팅 -&gt; 뼈대 -&gt; 표면/비주얼 은 원래 계속 오르락내리락하면서 개발하는거다. 한번에 다 되는 개발은 이상한 것 못해도 처벌받거나 비난받지 않을 믿음이 있는 분위기가 가장 중요. 좋은 조직은 심리적 안정감이 있다. 일을 정확하게 나눠서 서로 관심없이 개발할 수 있는 상황으로 관리자가 만들어도 -&gt; 품질이 안좋아지는 경우가 많음 계속 얘기하는게 좋음. 그게 애자일이지. 애자일 걍 앞에것들 잘하면 그게 애자일이 됨. 책 정리는 그렇고 개인적인 정리해보자면이번에 한 포인트 개편 작업은 제법 함께 자라는 개발이 아니었나 싶다.혼자 했으면 더 빨리 구현을 다 끝냈을것 같긴한데, 더 탄탄한 설계는 아니었을 것 같고 추후 운영시 리스크도 있었을듯특히 유난히 마음에 드는 부분들만 뽑아보자면,- 일의 정의, A : 그냥 일. B : A를 개선하는 일, C : B를 더 잘하기위해 하는 일. C는 학습이다.- 달인의 비결. `동기`와 `빠른 피드백`- 뛰어난 기술자는 타인과 인터렉션에 더 시간을 쓴다.- 소프트웨어 개발은 항상 `전략` -&gt; `범위지정` -&gt; `구조 셋팅` -&gt; `뼈대` -&gt; `표면/비주얼` 은 원래 계속 오르락내리락하면서 개발하는거다. - 한번에 다 되는 개발은 이상한 것- 심리적 안정감 구축" }, { "title": "Spring Batch 다양한 트리거방식", "url": "/posts/spring-batch-%EB%8B%A4%EC%96%91%ED%95%9C-%ED%8A%B8%EB%A6%AC%EA%B1%B0-%EB%B0%A9%EC%8B%9D/", "categories": "Blogging, Spring", "tags": "spring, spring-batch", "date": "2023-11-08 09:00:00 +0000", "snippet": "아래 항목들은 서로 짬뽕이 될 수 있다.트리거 방식 linux crontab : crontab -e 토이 프로젝트에서나 써라 어디서 돌리는지 제3자가 보면 절대 못 찾음, 로그도 보기 어려움 spring @Scheduled 이용 단일 인스턴스, 서버 한대로 돌릴때만 써먹을 수 있음. 2대면 같은 스케쥴에 2대씩 돌테니깐 장점 코드상에 박혀서 버전관리됨 단점 스케쥴 수정하려면 배포해야함 -&gt; 여기서부터 별로임 서버 한대로만해야하니깐 이중화 불가능함 직접 batch 돌리도록 구현 스케쥴 db 에 넣어놓고 트리거링하는애를 구현한다. 장점 내가 모든걸 컨트롤한다. 단점 귀찮음 jenkins 장점 위에 단점들을 다 완벽하게 커버 가능함. 단점 깔아야함. jenkins 띄우는데만 보통 메모리 2G~4G 씀. jenkins 까는 script 는 보통 관리 잘안하니까 이전설치하거나할떄 너무 빡침. job 셋팅 export 같은것도 지원은 하는데 잘 안됨. 설정 변경 히스토리가 의외로 안 남아서 오류나면 범인찾기 생각보다 어려움. 설정 변경 히스토리 남기려면 좀 귀찮음 버전 제한도 있는 듯함. https://blog.leocat.kr/notes/2020/10/15/jenkins-save-config-histories 실행 방식 mvc 로 띄워놓고 API 호출 이중화 가능. 일반 어플리케이션 처럼 그냥 빌드 배포 하는 느낌. jobExecutor bean 이용해서 실행시킨다 장점 spring 구동자체 하지도 않기 때문에(미리 해서 떠있으니깐) 실행속도도 제일 빠름 단점 배포할때 서버 내리고 띄우고 짓거리 해야하기 때문에 초기 셋팅 좀 불편해 어떤이유에서건 서버가 뜨질않으면 돌릴수가 없다. 서버를 튼튼하게 유지해야함. 이중화 필수 jar 빌드해서 갖다놓고 jar 실행 장점 job 마다 jvm 설정 다르게 줄수도 있음 빌드 결과물만 원하는곳에 갖다놓으면 되니깐 devops 셋팅 과정이 복잡하지않음 망했을때 서버들어가서 수동 jar 실행 계속하면, 장애 극복 가능. 단점 spring 띄워야해서 bean 이 많아지면 많아질수록 구동속도 느려짐 repo 체크아웃 받아서 gradle 빌드 실행 장점 커밋이 곧 서버 반영. reset 이 곧 롤백. 전환은 빠르다 단점 커밋이 곧 서버 반영이기 떄문에 인간 실수로 인한 사고날 수 있다.(가령 bean 설정 오류내서 spring 구동 안되면 모두 장애) 체크아웃 못 받으면 모든 배치 전면 장애 그냥 항상 배치 꺠지는걸 확인해서 의도적으로 알람 수신이 되는지 확인하라 : 테스트 코드처럼 떄떄로 java -jar 실패했는데, jenkins 상에는 SUCCESS 로 뜨고 그럴수 있음. 모두 인지 불가 까먹고 안적은게 있을수도 있다. to be continue" }, { "title": "함수형 프로그래밍과 모나드", "url": "/posts/%ED%95%A8%EC%88%98%ED%98%95%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%EB%AA%A8%EB%82%98%EB%93%9C/", "categories": "Blogging, Programming", "tags": "kotlin, functional", "date": "2023-04-17 09:00:00 +0000", "snippet": "책 정보 코틀린으로 배우는 함수형 프로그래밍 yes240. 시작하기 전에 모나드는 함수형 프로그래밍을 돕는 도구이다. 모나드 인터페이스 자체는 간단하나, 왜 얘가 함수형프로그래밍을 돕는지 이해를 하면 좋은 것 같다. 해야한다는 아님 모나드 법칙을 이해 안해도 함수형 프로그래밍 잘만 할 수 있을 것 같고, 새로운 모나드도 정의만 맞춘다면 구현할 수 있을 것 같다. map 과 flatMap 을 지원하면 된다. 현업에서 모나드를 우리가 구현해야 할 일은 사실 거의 없어보이긴한데, 기회가 되면 구현해보자.1. 모나드 타입 클래스interface Monad&lt;out A&gt; : Functor&lt;A&gt; { fun &lt;V&gt; pure(value: V): Monad&lt;V&gt; override fun &lt;B&gt; fmap(f: (A) -&gt; B): Monad&lt;B&gt; = flatMap { a -&gt; pure(f(a)) } infix fun &lt;B&gt; flatMap(f: (A) -&gt; Monad&lt;B&gt;): Monad&lt;B&gt; infix fun &lt;B&gt; leadTo(m: Monad&lt;B&gt;): Monad&lt;B&gt; = flatMap { m }} Webflux Publisher 기준으로 생각해보면 pure = of, just 같은거라고 보면 되는것 같다. fmap = map flatMap = flatMap. infix function 으로 사용가능 leadTo = then. infix function 으로 사용가능 2. 메이비 모나드sealed class Maybe&lt;out A&gt; : Monad&lt;A&gt; { companion object { fun &lt;V&gt; pure(value: V) : Maybe&lt;V&gt; = Just(0).pure(value) } override fun &lt;V&gt; pure(value: V): Maybe&lt;V&gt; = Just(value) override fun &lt;B&gt; fmap(f: (A) -&gt; B): Maybe&lt;B&gt; = super.fmap(f) as Maybe&lt;B&gt; override infix fun &lt;B&gt; flatMap(f: (A) -&gt; Monad&lt;B&gt;): Maybe&lt;B&gt; = when (this) { is Just -&gt; try { f(value) as Maybe&lt;B&gt; } catch (e: ClassCastException) { Nothing } is Nothing -&gt; Nothing }}3. 모나드 법칙 왼쪽 항등 법 : pure(x) flatMap f = f(x) 오른쪽 항등 법칙 : m flatMap pure = m 결합 법칙 : (m flatMap f) flatMap g = m flatMap { x -&gt; f(x) flatMap g } 함수 합성 관점에서 모나드 법칙identity compose f = ff compose identity = f(f compose g) compose h = f compose (g compose h)4. IO 모나드 함수형에서는 IO 기능이 아주 골칫거리임. DB조회, 호출, 파일읽기쓰기 그냥 분리하고 격리해라 하스켈 예시는 스킵5. 리스트 모나드sealed class FunList&lt;out T&gt; { companion object}object Nil : FunList&lt;kotlin.Nothing&gt;() { override fun toString(): String = \"[]\"}data class Cons&lt;out T&gt;(val head: T, val tail: FunList&lt;T&gt;) : FunList&lt;T&gt;() { override fun toString(): String = \"[${foldLeft(\"\") { acc, x -&gt; \"$acc, $x\" }.drop(2)}]\"}infix fun &lt;T, R&gt; FunList&lt;T&gt;.flatMap(f: (T) -&gt; FunList&lt;R&gt;): FunList&lt;R&gt; = fmap(f).flatten()infix fun &lt;T, R&gt; FunList&lt;T&gt;.fmap(f: (T) -&gt; R): FunList&lt;R&gt; = when (this) { is Nil -&gt; Nil is Cons -&gt; Cons(f(head), tail.fmap(f))}나머지 뒷장 로깅 함수 중간에 로깅 -&gt; 별루 -&gt; 확장함수 withLog 붙이면? 부수효과.. 순수함수 오염시킨다 private fun functionalSolution2(list: FunStream&lt;Int&gt;) = list .fmap { addFive(it) withLog \"$it + 5\" } .fmap { square(it) withLog \"$it * $it\" } .fmap { isGreaterThan50(it) withLog \"$it &gt; 50\" }private infix fun &lt;T&gt; T.withLog(log: String): T { println(log) return this} WriterMonad 이용하자 data class WriterMonad&lt;out T&gt;(val value: T, val logs: FunStream&lt;String&gt;) : Monad&lt;T&gt; { companion object { fun &lt;V&gt; pure(value: V) = WriterMonad(0, mempty()).pure(value) } override fun &lt;V&gt; pure(value: V): WriterMonad&lt;V&gt; = WriterMonad(value, mempty()) override fun &lt;R&gt; flatMap(f: (T) -&gt; Monad&lt;R&gt;): WriterMonad&lt;R&gt; { val applied = f(this.value) as WriterMonad&lt;R&gt; return WriterMonad(applied.value, this.logs mappend applied.logs) }} 예외처리 메이비 모나드를 쓰면 사실 해결이 됨. Optional.empty() 이더 모나드로 사유 기록 가능 트라이 모나드 확장 가능. 테스팅 우선 테스트하기 좋은 순수함수를 만들어라. kotlintest 쓰면 알아서 string 만들어주기도 함. FunList 같이 직접 만든 객체 랜덤은 생성못하니, generator 를 만들어서 넣어줘야함 근데 우린 junit 쓸 예정. class FunListTest: StringSpec({ \"testReverse\" { forAll { a: String -&gt; reverse(reverse(a)) == a } } }) 디버깅 보통 고차함수 + 게으른 실행이라.. 그냥 람다 함수 중간에 break point 찍어라 함수형 프로그래밍 마무리 1장 내용인데 까먹었으니깐 불변성, 참조 투명성, 일급함수, 게으른 실행, 타입 안정성 순수 함수 동일 입력 동일 출력 부수효과가 없다. 예외발생도 부수효과 객체 상태 변경 공유 변수 수정 db 조회 그럼 함수형 프로그래밍은 db 조회하지마? 격리를 해서 최대한 순수함수를 만들고, 부수효과 일으키는 애는 격리를 하자 " }, { "title": "인프런 스프링 Spring 핵심 원리 (기본)", "url": "/posts/%EC%9D%B8%ED%94%84%EB%9F%B0-%EC%8A%A4%ED%94%84%EB%A7%81-%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC/", "categories": "Blogging, Spring", "tags": "spring", "date": "2023-04-11 09:00:00 +0000", "snippet": " 이 게시물은 김영한 - 스프링 핵심 원리 요약임 모든 코드는 OsoriAndOmori/playground-spring 에 올려둠. 멋대로 만든 프로젝트 구조 이기 떄문에, 강좌 내용은 따라가나 구조는 절대 따라가지 않음..객체지향 설계와 스프링 스프링을 알기위해선 그 과거를 알아야한다. 그건 ejb. 지옥같은 ejb 의존성. 굳이 찾아서 볼 필요는 없을것 같다. 여기서 탈피하자면서 POJO 라는 개념이 나옴.. 플레인 자바 오브젝트. 스프링은 객체지향을 잘 개발할 수 있게 도와주는 도구인데, 그럼 좋은 객체지향은 뭐냐 대체 좋은 객체지향 설계 원칙 : SOLID 로버트 마틴 아저씨 5가지 원칙이 있다. 그 중 OCP 개방폐쇄(다형성으로 극복), DIP 의존관계(인터페이스에 의존해라) 역전 원칙 결국 좋은 객체지향 설계는 역할(인터페이스) 과 구현(클래스) 에서 역할에 초점을 맞춰야한다. 다형성. 쓰는 클라이언트는 역할(인터페이스)만 보고 개발을 하면 되는것. 구현은 갈아낄 수 있다. (자동차, 테슬라, 현다이) 이 설계의 한계는 역할 잘못 설계하거나 변경해야하면 그냥 개망한다는거 ㅋㅋ java default 꼴 난다. 그런데 스프링이 없을떄 구현 클래스 내 아무리 원칙 잘 지키려고해도 MemberRepository m = new MemoryMemberRepository() 이걸 쓸수 밖에 없음. =&gt; DIP 위반 그럼 DIP 를 지키려면 결국 외부에서 저 필드에 주입을 해주는 방법밖에 없음. =&gt; 그래서 나온게 스프링 컨테이너이다. 결국 모든 사람은 SOLID 를 지키려면 여기에 도달할 수 밖에 없다. 결국 이상적으로는 모두~ 인터페이스로 먼저 만들어두면, 하부 구현 기술 선택을 최대한 미룰 수 있다. 갈아끼기도 좋다 =&gt; 유지보수 좋음 근데 진짜 실무에서 다 구현하기엔 추상화라는 비용이 발생.. 너무 개짜증남. 기능을 확장할 생각이 없으면 구체 클래스, 리펙터링해서 인터페이스 도입해도 될 듯. 맨 땅 자바코드로 스프링 컨테이너 만들어보기 시작 순수 자바와 junit 만으로 회원, 주문 시스템으로 개발해보자 멤버, 멤버Service, 멤버Repo, 주문Service, 할인 정책 만들면 끝. interface(역할)과 class(구현) 해서 설계해놓고 하나씩 구현해보자. 다 만들어 놨더니, 할인 정책을 아예 바꾸고 싶다고 나옴 -&gt; 후후 객체지향설계를 잘 해놨지 Policy 만 Service 에 바꿔끼는데 =&gt; 이게 문제가 발생함. 클라이언트의 코드를 수정했음… OCP, DIP 다 어겼다. 이 문제를 어떻게 해결할 수 있을까? 누군가가 interface 의 구현체를 생성하고 주입 을 해줘야한다. 관심사의 분리 공연이 있다면, 역할(interface) 가 있고, 배역(class) 이 있는데 공연에서 배우는 누가 데려오는가? 전체 공연 기획자가 하는게 맞다 -&gt; 벗 기존코드는 로미오가 줄리엣을 직접 섭외 해 온 것과 같다. 공연 기획자가 필요하다. 로미오가 공연도하고, 섭외도해야하는 사람이 되었다. 관심사의 분리가 필요하다. 자기 배역에만 충실해야한다. AppConfig.java 에서 만들어서 한 곳에서 만들고 주입을 한다. =&gt; 여기서 생성자 주입(DI) MemberService 입장에선 구현클래스 생각없이, 인터페이스가 저장하랬어하고 저장하면되는거야 public class AppConfig { public MemberService memberService () { return new MemberServiceImpl(memberRepository()); } public OrderService orderService () { return new OrderServiceImpl(memberRepository(), discountPolicy()); } public MemberRepository memberRepository () { return new MemoryMemberRepository(); } public DiscountPolicy discountPolicy(){ return new FixDiscountPolicy(); }} 여기서 FixDiscountPolicy -&gt; RateDiscountPolicy 로 변경하면 =&gt; 아주 간단하게 정책 변경 됨. 전혀 클라이언트 코드를 변경하지 않음. 구성 변경은 해야지 당연히. 구성 영역만 변경을 하면, 실행영역은 전혀 건드리지 않게 된다. OCP 와 DIP 를 만족하는 코드 완성. 의존성 주입을 사용하면, 정적인 클래스 의존관계(import)를 변경하지 않고 동적인 클래스 의존 관계를 변경 할 수 있다. 결국 AppConfig 가 IoC 컨테이너, DI 컨테이너 임. 스프링 컨테이너와 스프링 빈 빈 전체 생성 -&gt; 빈 의존성 연결 하는 프로세스를 거친다. 스프링 컨테이너는 설정 정보를 참고해서 의존관계를 주입한다. 그런데 자바코드를 보면 생성하면서 의존관계를 만들수밖에 없지않나 싶은데? 좀 나중에 더 설명 예정 빈 가져오기 getBean, getBeanType 부모 타입으로 조회시, 자식들 다 나옴. 당연히 여러개 있으면 NoBeanUniqueException… 빈 설정은 리턴을 interface 로 하는게 유연하니간 참고. BeanFactory 와 ApplicationContext = 스프링컨테이너 = 스프링의 핵심 인터페이스로 기능을 파악하는 개발자가 되어보자.. AnnotationConfigApplicationContext 기준으로 내부적으로 BeanDefinitionReader 가 있음. 실제 자바 코드 읽어서 BeanDefinition 이라는 메타정보를 만들어 저장. 직접 BeanDefinition 구현해서 등록도 가능한데, 그렇게 하진않겠지… 싱글톤 private 생성자로 직접 로직추가해서 싱글톤 구현 가능. 싱글톤은 대신 단점이 많다. 보일러플레이트 코드가 많아진다. (클래스별로 getInstance 다 추가) OCP DIP 위반. 클라이언트 코드가 구현클래스에 의존하게 됨. 스프링컨테이너는 객체 인스턴스를 미리 만들어서 집어넣어둠. 어떻게 위 단점을 회피했는지는 안알려주고, 뭐 대충 얘가 해주니 우리가 OCP 를 위반할일은 없다는 느낌인 듯. 주의점 ㅋㅋ 당연한거지만 빈에다 멤버변수 만들고 동적으로 바꾸는건 절대 안 됨. Stateless 하게 만들어야함, 읽기만 하는 용도로 만들어야함. @Configuration 과 싱글톤 @Configuration 내부 보면 memberService 만들때 한번 new memberRepository 하면서 생성하고 orderService 만들 때 또 memberRepository 생성함. 그럼 싱글톤 꺠지는거 아님? CGLIB 로 기존 클래스를 상속하는 class 를 만들어 메서드 override 만들어서 이를 해결함. 바이트 코드 조작으로 아마 이렇게 바꿔 줄것으로 예상. @Beanpublic MemberRepository memberRepository () { if(스프링 컨테이너에 있으면) return 스프링컨테이너.getbean(memberRepository) else return new MemoryMemberRepository();} @Confiruation 안붙인 설정파일이면, Bean 만들긴 하는데 CGLIB 안써서 만들기 떄문에, 싱글톤이 아니게 됨. 스프링 컨테이너가 관리하는 애도 아니게 됨. 그냥 붙여라. 컴포넌트 스캔 아는거니깐 패스 @ComponentScan, @Service, @Repo, @Controller 관련 이야기의존관계 자동 주입 생성자 주입을 사용하자 테스트할 때 의존성 명확함 -&gt; 많으면 구조 분리의 신호 불변! @Annotation 을 만들어서 @Qualifier 품으면 좀더 명확하게 쓸 수 있음 (스프링에서 제공하는기능임. 상위 읽어서 쓰는) @Target({ElementType.FIELD, ElementType.METHOD, ElementType.PARAMETER,ElementType.TYPE, ElementType.ANNOTATION_TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Qualifier(\"mainDiscountPolicy\")public @interface MainDiscountPolicy {} 후보 빈이 많을 경우 list 도 map 도 다 받을 수 있음. map 으로 받아서 써야겠음 다음부터 수동(@Bean) 자동(@Component) 등록빈 언제 하는게 좋을까 그냥 느낌대로해 답은 없다. 비즈니스 -&gt; 자동등록 다형성을 지원하는 비즈니스 객체는 수동등록을 고려해보자. (list map 으로 받을것들) 기술지원로직 -&gt; 수동등록이 일반적 근데 스프링부트가 지원 잘하는 Datasource 같은건 그냥 자동등록쓰자 내가 직접 만드는 기술지원 로직은 수동하자 빈 생명주기 콜백 스프링 빈은 간단하게 아래와 같은 라이프사이클을 갖는다. 기본적으론 객체 생성 -&gt; 의존관계 주입인데 생성자 주입의 경우 생성하면서 바로 의존관계 설정해줌. 빈 초기화라는 말은 결국 빈 생성만 한걸 말하진않음 -&gt; 의존관계 설정까지 다하고 callback method 를 줘서 다 만들고 초기화할 수 있게 해줌. 스프링 컨테이너가 종료되기 전에 소멸 콜백을 줄 수도 있음. 객체 생성과 초기화를 분리하자생성 = 진짜 클래스 그냥 만드는거, 초기화 = 네트워크 연결 및 무거운 로직단일 책임의 원칙! 스프링 생명주기 콜백 인터페이스 InitializingBean, DisposableBean 스프링 전용 인터페이스임. annotation 정도면 모르겠는데 코드레벨까지 가져와야하는 단점이 좀 있음. 내가 코드를 고칠 수 없는 외부 라이브러리에는 당연히 적용할수가 없음. InitializingBean -&gt; affterPropertiesSet DisposableBean -&gt; destroy 더 나은 방법들이 있어서 이제 잘 사용하진 않음 (2003년에나 만들었던 방법) @Bean 의 destroyMethod, initMethod destroyMethod 는 INFERRED 값이 기본값으로 약간 알아서 close shutdown 메서드 동작 시켜줌 @PostContruct, @PreDestroy 스프링 권장사항 javax.annotation 에 들어있음. 자바진영 그냥 공식 JSR-250 자바 표준 빈 스코프 종류 싱글톤 프로토타입 : 스프링 컨테이너는 프로토타입 빈을 생성하고, 의존관계 주입, 초기화까지만 처리함. @PreDestroy 호출해주지않음. request : 요청에서 하나 프로토타입을 싱글톤과 같이 사용하는 경우 문제점 (싱글톤 빈 A에서 프로토타입 빈B를 주입받아 사용하는 경우) 아마 개발자의 의도는 호출할떄마다 B의 프로토타입 새로운 객체가 생성되길 바라는건데, 이렇게되면 최초 싱글톤 빈 A 만들때, 그냥 Prototype 빈을 호출해서 들고 있는것이 될 뿐 의도대로 동작하는 것은 아님. 결국 그냥 싱글톤 빈들을 사용하는것 밖에 안됨. 해결 방법 : ObjectProvider(스프링), Provider(자바표준) 사용 얘네는 대리자 정도임. 가운데 프록시라고 생각하면되고, .get() 으로 매번 가져올수있음. 스프링 컨테이너가 이걸 뜨면서 bean 으로 등록하나봄 자바 표준과 스프링 표준 겹치면 그냥 스프링꺼 쓸래.어차피 프레임워크 바꾸면, 그냥 처음부터 다시 만드는 세상인데 ㅎㅎ 웹 스코프 웹 환경에서만 동작하는 빈 스코프 얘도 웹 요청이 와야 스프링에서 bean 만들어서 던져줘야하니까 웹 스코프 빈도 Provider 를 통해 감싸서 빈에서 받아야한다!! @Controller @RequiredArgsConstructor public class LogDemoController { private final LogDemoService logDemoService; private final ObjectProvider&lt;MyLogger&gt; myLoggerProvider; 스코프 프록시 아 근데 Provider 로도 감싸고 싶지가 않아 그냥 쓰고싶어 하는놈들이 만들어낸 기능 Enhancer 로 짝퉁만들어넣은다음에, 실제 호출할때 Provider 동작하는것 처럼 하게 해줌. @Component@Scope(value = \"request\", proxyMode = ScopedProxyMode.TARGET_CLASS)public class MyLogger {} 아무튼 대부분의 비즈니스 문제는 싱글톤으로 대부분 해결이 가능한데, 굳이 막 쓰진 말자. 유지보수 정말 어려워 질수도 있음." }, { "title": "정해진 미래", "url": "/posts/%EC%A0%95%ED%95%B4%EC%A7%84-%EB%AF%B8%EB%9E%98/", "categories": "Blogging, Book", "tags": "인구학", "date": "2023-03-07 09:00:00 +0000", "snippet": "책 정보 정해진 미래 조영태 yes24현재가 아닌 미래 보자 인구학적 관점으로 보면 대부분의 일들은 예측이 가능함. 2023 년이 되어서야 저출산 빨간불로 온나라가 들썩이고 있지만, 이미 2002년부터 진행됨. 이미 늦었다. 지금부터 1.5명씩 낳아도 지난 20년간 쌓인 인구문제는 발생할 것이다. 저출산 -&gt; 가족의 크기의 변화 -&gt; 4인 가족은 없다. 가족에 대한 이미지 변경 25년되면 1~2인 가구가 60% 이상 그중 60%는 노인일 것. 4인 가족은 없어졌으니 -&gt; 집이 영향을 받는다. 소형아파트 24평형이 구매 활발해질까? 서울 20년간 소형평수 공급보단, 중소형, 중대형 평수 공급이 더 비율이 높았음 (잘못된 공급정책) 젊은 사람은 경제활동 시기가 늦어짐에 따라, 구매력은 더 떨어져 소형평수도 사기 힘들어지고, 노인들은 변화보단 눌러 앉게되어 부동산 거래는 침체 될 것이라고봄 -&gt; 공인중개사 따면 안되겠다.. 부동산 불패신화가 이젠 아닐 수도 있다. 가격이 떨어져야 미래가 있다. 부동산 부양정책은 역효과를 부를수 있다. 억지로 부양정책 한것이 한번에 리턴으로 올 수 있다. 교육환경 개인의 경제수준 결정 3요소 : 교육, 직업, 소득 뒤에 두개는 교육이 기반 특히 우리나라의 경우.. 심지어 교육과 건강지수도 비례함. 건강에 대한 태도 또한 교육으로 만들어지기에. (고졸, 대졸 기대수명 연구 결과) 교육 과잉공급을 향해 달려가는 중 (인프라, 인적자원 둘 다) 초 중 고, 선생님 만명씩(정규직만) 해고를 해도 1인당 담당학생이 15명임. 지금은 부담임까지 두는중 베이비부머 교사가 은퇴를 해도 달라지는건 없음. 사범대 정원이 계속 늘면서 왔기 떄문 학교도 500개 씩은 없어져야할 상황. 대입 경쟁률. 25년쯤엔 경쟁률 인서울 4년제만 놓고봤을때 4대1 까지 떨어짐. 4명만 제끼면 인서울 4년제 가능함. 물론 정원조절이 되며 조금더 높겠지만, 맥락은 비슷. 대학은 또 계속 증가해옴. 아마 대부분 문을 닫을 것. 대학은 시장논리로 움직임. 고등학교까진 공공재 개념. 레드오션에 발을 들일때는 그 기득권층의 숫자가 은퇴할때가 진입할 수 있는 시기 베이비부머 은퇴 시기에 맞는 진입. 사교육은 줄어들 것이다. 이틈에 공교육이 변화한다면 더욱 좋겠다. 그 시작은 교육부로부터.. 교습법 등 경쟁자의 크기를 생각하는 교육을 하자.취업 40만명씩 태어나는 아이들의 미래가 밝지않다. 대학진학률이 너무 높다. 베이비부머땐 고성장 + 진학률 38%, 지금은 저성장 + 진학률 70%, 심지어 자동화기계 / 인공지능과까지 경쟁해야한다. 위가 나가지도 않음.대학은 쉽게가도 취업은 어려울 것. 지금 20대보다 10대의 미래가 더 어둡다. 자녀교육에 매몰된건 전통적인 사고방식에서 온 것으로 보임. 다음 세대는 대학 진학률도 좋고, 취업은 운좋게 쉬울지 모르지만 고령화의 함정에 당해 팍팍할 것이다. 삼성전자는 중위나이 27세 인도네이사와 베트남에 공장을 짓고 20만명의 일자리 창출을 하고 있다. 중위나이 44세인 우리나라는 인건비 비싸기만하고 게속 인건비는 늘어나니깐 우리나라 20만명 일자리를 잃은거임. 기업은 이렇게 해외로 고개 돌리는중. 건강 &amp; 밥그릇 가족이 기능을 했던 건강 관리가 이제 동작 더 이상 안하고 1~2인 가구가 되며 사회가 그 책임을 떠안게되었음. 걍 구성원이 아프면 사회적 비용이 계속 발생함. 다 돈임. 건강 프로모션 필요. 정치는 분명히 베이비부머 위주의 고령화 정책이 계속 될 것으로보임. 표 얻기 위해서. 깡 숫자가 너무많아서 정치에 영향력이 너무 높다. 기득권이 포기하지 않으면 한국사회는 나빠진다고 밖에 전망할 수 없음. 대안 노동 시장은 유연해질 수 밖에 없다. 철밥통은 점점 사라질 것. 먹고살기 팍팍해지면 어쩔수가없다. 건물주도 마냥 좋을까? 핫플레이스가 아니면 거래가 줄어들 것이다. 공실이 늘어날수 있다. -&gt; 그 비용은 건물주 몫 프리타 족이 많이 나올수도있다 (프리랜서 알바족) -&gt; 고용불안, 저임금으로 일본에서 지금 매우 사회문제로 인식된다. (최저시급이 높아질수록 많아질 것) 일본은 알바비가 비싸서 상관없는데, 우리나라는 혼자 못 살아서 저출산 강화가 될것. 인재 유출. 젊은사람이 해외 나가서 일하고 세금은 나라로 들어오도록 국가적 지원 필요. 시스템을 갖춘 생존전략 : 기반 마련해주고 어느정도 다져지면 알아서해라 라는걸 기조로 삼아 1인 창업자도 지원 필요하다. 글로벌 서비스 회사.대안은 해외에 있는가 인구학자에게 가장 중요한 인구 구성 성분은 “연령”. 많은 인구정책은 결국 연령구조를 어떻게 만들까에 관한 논의로 만들어짐. 조선족(재혼) 및 동남아(초혼) 국제 결혼이 줄어드는 추세. 농촌에서 보통 이렇게 결혼하는데 농촌이 줄고 있으니깐. 다문화정책 인척하는 사람들의 동화 요구도 문제작은 대한민국을 준비하자 다 단점뿐이다 입시 좋아짐 생애주기의 다양성. 숫자가 줄어드니 획일화 탈피가능하다. 부동산도 떨어지며 내수시장 위축, 경기 침체가 올 수도 있다. 자꾸 내수시장이 줄면 기업은 해외로 눈을 돌리고 또 일자리가 줄어든다 그마만큼 일본과 같은 연착륙이 가능할까 기초체력이 다름. 내수시장(인구 1.2억, gdp 3위, 뭐든지 시작이 /빠름) " }, { "title": "Spring Security 요약 (~ing)", "url": "/posts/spring-security-summary/", "categories": "Blogging, Spring", "tags": "spring, spring-mvc, spring-security", "date": "2022-07-26 05:00:00 +0000", "snippet": " 이 게시물은 백기선 - Spring Security 요약임 모든 코드는 OsoriAndOmori/playground-spring 에 올려둠. 멋대로 만든 프로젝트 구조 이기 떄문에, 강좌 내용은 따라가나 구조는 절대 따라가지 않음..1. 스프링 시큐리티 연동 gradle dependency 추가 implementation 'org.springframework.boot:spring-boot-starter-security' 추가를 하게 되면 기본적으로 모든페이지는 인증(Authentication) 을 하게됨. 로그인 페이지도 기본적으로 제공이 됨. 스프링 구동시 로컬 환경에서 쓸 수 있는 기본 비밀번호가 주어짐. 아이디는 user2022-07-26 14:33:05.315 WARN 14922 --- [ main] .s.s.UserDetailsServiceAutoConfiguration :Using generated security password: f93ee0c0-f58b-4f39-ab94-7805c203d2d5This generated password is for development use only. Your security configuration must be updated before running your application in production. 해결해야할 숙제 인증없이 접근 가능한 URL을 설정하고 싶다. 이 애플리케이션을 사용할 수 있는 유저 계정이 그럼 하나 뿐인가? 비밀번호가 로그에 남는다고? 2. 인증없이 접근 가능한 URL 설정 SecurityFilterChain Bean 등록하면 끝임. chaning 형태로 and() 활용하여 예쁘게 쓸 수도 있고 그냥 끊어서 해도 상관없음. 아래 예제는 /, /info 는 모두에게 접근 허용하고, /admin 의 경우에는 ADMIN role 을 가지고 있는 자만이 접근 가능함. @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http.authorizeRequests() .mvcMatchers(\"/\", \"/info\").permitAll() .mvcMatchers(\"/admin\").hasRole(\"ADMIN\") .anyRequest().permitAll(); http.formLogin(); //폼로그인 http.httpBasic(); //http 기본 로그인 return http.build(); }3. jpa &amp; database 연동 jpa 쓰고 싶으니깐 jpa dependency 추가 하고 테이블이랑, repository 하나 만들어줌 implementation 'org.springframework.boot:spring-boot-starter-data-jpa'public interface AccountRepository extends JpaRepository&lt;Account, Integer&gt; { Account findByUsername(String username);}@Entity@Datapublic class Account { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; @Column(unique = true) private String username; private String password; private String role; //spring security 가 원하는 기본적인 비밀번호 포맷 {알고리즘} public void encodePassword() { setPassword(\"{noop}\" + getPassword()); }} db 연동시 핵심은 UserDetailsService 를 구현한 Bean 이 있어야함. 등록만 하면 바로 적용됨. 여기까지 새로운 문제 {noop} 을 없앨 수는 없을까? 테스트는 매번 화면키고 해야 하는건가? 4. Password Encoder 적용 spring 5 이전엔 따로 PasswordEncoder 없이, 그냥 문자 그대로 저장했었음. (아님 사용자가 직접 해시 알고리즘 써서 비번 바꾸거나겠지?) 왜 맨 앞에{noop}포맷이 생겼을까라고 한다면, 4.x 대 까진 NoOpPasswordEncoder 가 기본이었는데 버전을 올리면 Bcrypt 로 변경됨 그러다보니 버전업을하면 인증이 전부 꺠지게됨… 그래서 앞에 prefix 를 통해, 여지를 주기위해 포맷을 저렇게 잡았음. 아래 bean 을 추가해주고 최초 유저 집어넣을 떄 비번 encoding 한번 해주자. 그러면 기본 bcrypt 로 셋팅 되어서 비밀번호가 저장됨. 원하면 포맷을 {MD5}도 변경할 수 있음. 로그인시 PasswordEncoder bean 이용해서 인증 실시함. @Bean public PasswordEncoder passwordEncoder() { return PasswordEncoderFactories.createDelegatingPasswordEncoder(); } public void encodePassword(PasswordEncoder passwordEncoder) { this.password = passwordEncoder.encode(this.password); } 여기까지 새로운 문제 테스트는 매번 화면키고 해야 하는건가? 5. Spring security test 화면 키고 테스트하기 매우 귀찮음. @WithMockUser(username = \"admin\", roles = \"ADMIN\") 같은걸 사용해서 유저 권한 체크 가능함 @Test @Transactional void login() throws Exception { String username = \"sky-test2\"; String password = \"sky-test2\"; Account user = createUser(username, password); mockMvc.perform(formLogin().user(user.getUsername()).password(password)) .andExpect(authenticated()); }6. Spring Security Architecture1. SecurityContextHolder 와 Authentication SecurityContextHolder ThreadLocal 에서 SecurityContext 제공함. ThreadLocal 은 한 쓰레드 내에서 공유하는 저장소라고 일단 생각 (메서드 파라미터로 안넘겨도 가져올 수 있는 데이터) SecurityContext.getContext().getAuthentication() //하면 해당 요청의 인증정보 꺼낼 수 있음. Authentication 의 실제 구현체 UsernamePasswordAuthenticationToken 같은 클래스로 구현되어있고 폼로그인시 요걸 사용함. AuthenticationManager SecurityContextHolder 가 Authentication 을 들고 있는거고 얘는 실제 인증을 담당하는 매니져임 내부에 authenticate 메서드 하나만 들고 있음. 실제 구현체는 ProviderManager 를 사용함. debuger 를 여기다 찍고 한번 보셈. " }, { "title": "Spring batch Mysql + JdbcCursorReader 사용시 확인할 점", "url": "/posts/spring-batch-jdbc-cursor-reader/", "categories": "Blogging, Spring", "tags": "spring, spring-batch", "date": "2022-07-23 09:00:00 +0000", "snippet": "mysql 에서 JdbcCursorReader 를 사용했는데 뭔가 이상한 부분 확인 분명히 fetch size 2 로 지정했는데, reader 의 doRead() 를 디버깅해볼시 전체 데이터를 들고 있음. 그리고 결과 값이 ResultSetRowsStatic 임. cursor 를 똑바로 썼으면 ResultSetRowsCursor 임 @Beanpublic JdbcCursorItemReader&lt;SomeThing&gt; reader(DataSource dataSource) throws Exception { JdbcCursorItemReader&lt;SomeThing&gt; reader = new JdbcCursorItemReaderBuilder&lt;SomeThing&gt;() .name(\"cursorTestReader\") .dataSource(dataSource) .fetchSize(2) .verifyCursorPosition(false) .rowMapper((rs, rowNum) -&gt; something) .sql(\"SELECT * FROM table\") .build(); reader.afterPropertiesSet(); return reader;} 본래 JdbcCursorItemReader 는 fetchSize 만큼만 데이터를 들고, 다 소비하면 db 에 다음 데이터를 요청해 적은양의 메모리로 무한한 대용량을 처리 할 수 있는 Reader 임. 물론 큰데이터를 저용량으로 처리하면, 시간이 오래걸려서 그만큼 Connection + Transaction 을 길게 가져가게 되는 문제가 있음.한번에 데이터를 메모리에 다 올리게되면 일단 저렇게 다 올라가면, 메모리 용량 이슈를 피할 수 없고, CursorReader 를 쓰는 이점을 모두 잃게됨 왜 Why? 동작을 하지 않는 것일까..?CursorReader 의 장점과 사용처 적은 메모리에 Cursor 를 움직이며 ‘조금씩’ 데이터를 가져옴. //ResultsetRowsCursor.java @Overridepublic Row next(){ if(this.fetchedRows==null&amp;&amp;this.currentPositionInEntireResult!=BEFORE_START_OF_ROWS){ throw ExceptionFactory.createException(Messages.getString(\"ResultSet.Operation_not_allowed_after_ResultSet_closed_144\"), this.protocol.getExceptionInterceptor()); } if(!hasNext()){ return null; } this.currentPositionInEntireResult++; this.currentPositionInFetchedRows++; // Catch the forced scroll-passed-end if(this.fetchedRows!=null&amp;&amp;this.fetchedRows.size()==0){ return null; } if((this.fetchedRows==null)||(this.currentPositionInFetchedRows&gt;(this.fetchedRows.size()-1))){ fetchMoreRows(); this.currentPositionInFetchedRows=0; } Row row=this.fetchedRows.get(this.currentPositionInFetchedRows);} private void fetchMoreRows() { if (this.lastRowFetched) { this.fetchedRows = new ArrayList&lt;&gt;(0); return; } this.protocol.sendCommand( this.commandBuilder.buildComStmtFetch(this.protocol.getSharedSendPacket(), this.owner.getOwningStatementServerId(), numRowsToFetch), true, 0); Row row = null; while ((row = this.protocol.read(ResultsetRow.class, this.rowFactory)) != null) { this.fetchedRows.add(row); } this.currentPositionInFetchedRows = BEFORE_START_OF_ROWS; ....} chunk size 가 차면 writer 로 데이터를 넘기지만, 연결을 끊지 않고 커넥션 유지. 너무 오래걸리는 처리의 경우 transaction 이 길어짐 멀티쓰레드로 하지 못해서 처리가 너무 오래걸리는건 느릴 수 있음. 적은 메모리로, 초대용량 처리를 할 수 있음. 커넥션 타임아웃만 길게 잡으면 무한에 가까운 처리 가능. 와이어샤크로 볼 시 DB에서 데이터를 가져와야하기 떄문에 네트워크 입출력 횟수가 많을 수 밖에 없음.mysql 에서 정상적으로 사용하고 싶을 시 옵션을 추가해야함 mysql-connector-java 드라이버가 깡으로는 cursor fetch 기능을 사용하지 못하게함. jdbc:mysql://localhost/?useCursorFetch=true connection 맺을 때, 이 옵션을 주지 않으면 Cursor의 기능을 쓸 수 없음. 누락시 그냥 일반 쿼리처럼 한번에 전체 데이터를 가지고 오게됨.자매품 maria db 에선 어떨까 maria db 드라이버는 훌륭하게 지원함. 아무 옵션 없이 그냥 바로 사용 가능함. maria db 구현체는 StreamingResultSet.java 인데, 개발자가 지정한 fetchSize 사이즈만큼 응답을 넘겨줍니다.결론 장비가 보통 빵빵한 회사에선 쓸일이 많이 없다. 거의 무한한 데이터를 처리할 떄 장애 없이 효율적일 것이다.참고 블로그 https://heowc.dev/2019/02/09/using-mysql-jdbc-to-handle-large-table-1/ https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-implementation-notes.html" }, { "title": "Spring batch PagingReader 로 Update & Delete 시 데이터 처리 누락되는 경우", "url": "/posts/spring-batch-paging-reader-update-delete/", "categories": "Blogging, Spring", "tags": "spring, spring-batch", "date": "2022-07-21 09:00:00 +0000", "snippet": " Spring batch 의 ChunkOrientTasklet 에서 Reader 를 PagingItemReader, Writer 에선 삭제 Operation 을 할 때, 누락이 발생할 수 있음을 알리는 글 입니다.Chunk 단위 Transaction 처리 spring batch 는 chunk 단위로 처리를 합니다. 처리할 전체를 읽어서 한번에 넘기는 방식이 아닌! 일부를 읽고 그 일부를 처리한 뒤 commit 하는 사이클을 반복하는데요. 그 chunk 의 사이즈는 step 을 구현할 때 .chunk(int size) 를 통해서 설정합니다.@Beanpublic Step step1() { return this.stepBuilderFactory.get(\"step1\") .&lt;String, String&gt;chunk(chunkSize) // 요기서 .reader(fooReader()) .processor(fooProcessor()) .writer(compositeItemWriter()) .stream(barWriter()) .build();}PagingItemReader 에 관하여 pagingReader 의 경우 한번 읽을 때 가져오는 데이터 양인 fetch size 를 셋팅하는 옵션이 무조건 있습니다. (chunk 개념과 다릅니다.) chunk-size 와 reader fetch size 가 10 으로 같다고 가정할 해봅시다. 그러면 한번 10개 Read -&gt; 한번 10개 Write 를 반복하게 됩니다. 1번부터 10번까지 한번 가져오고, 10개를 건너뛰고 11번부터 20번 까지 한번 가져오는 식으로 동작을 하는데요. 10개를 건너뛰고 이것 때문에 이 글을 쓰게 되었네요.실제 설정은 아래와 같이합니다.@Beanpublic JdbcPagingItemReader itemReader(DataSource dataSource, PagingQueryProvider queryProvider) { Map&lt;String, Object&gt; parameterValues = new HashMap&lt;&gt;(); parameterValues.put(\"status\", \"NEW\");\t return new JdbcPagingItemReaderBuilder&lt;CustomerCredit&gt;() .name(\"creditReader\") .dataSource(dataSource) .queryProvider(queryProvider) .parameterValues(parameterValues) .rowMapper(customerCreditMapper()) .pageSize(1000) //처음 조회는 1번 ~ 1000번, 그 다음은 읽을 떈 \"1000개 건너뛰고\" 1001번 ~ 2000번 .build();}조건을 건 Update &amp; Delete Write 시 Paging Reader 로 읽을 때 데이터가 누락되는 현상 일반적으로 스프링 배치를 데이터를 읽고 처리해서 다른곳으로 마이그레이션 하는 용도로 많이 사용하는데요. 지울 때는 잘 생각해서 Reader 를 구성해야합니다. 문제 발생 flow 처음에 Reader 가 10개를 가져옴 -&gt; writer 로 10개를 넘겨서 삭제 페이지 하나 증가해야하니, 두번째 Reader 가 10개를 건너뛰고 10개를 가져옴 -&gt; writer 로 10개를 넘겨서 삭제 2번의 단계에서 지워야할 10개를 건너뛰었습니다. 그렇게 계속 프로세스가 진행이되면 다 끝나고 난뒤 딱 절반정도만 지우게 됩니다. 결과 : 이빨이 빠지는 느낌으로 chunk 단위 실행이 될 때마다 한 뭉탱이씩 읽는것을 누락합니다. 이는 한번 읽기를 진행되고나면 page++ 를 하고 쿼리 실행시 getPage() 를 하는 문제로 인해 발생합니다. 대응방법1. 지울 데이터보다 chunk size 를 크게 잡는다. ( =한 번의 트랜잭션으로 끝낸다.) 무식하지만 쉽습니다. 네트워크 리소스도 많이 쓸 필요 없이, 일괄로 모아서 한방에 보내버리는 방법이죠. 다만 데이터가 큰 경우 WAS 의 Heap 메모리를 많이 차지하게 되고, DB 로 한번에 넘길 시 갑작스런 DB 부하도 주어질 수 있습니다. DB 부하를 덜주는 방법으로는, 아래처럼 writer 를 직접 구현해서 일정 partition 별로 나눠서 지우게 하는 방법이 있지만, 어플리케이션은 데이터를 전부 메모리에 들고 있어야하는건 사실입니다. 필드 6개 정도 가지고 있는 Java Object 20만개의 메모리 용량이 200MB 정도 됩니다. for(List&lt;Object&gt; writes : 50개씩 나눠서 2차원 배열로 만든 전체 데이터) insert(writes) intellij 에 자체적으로 들어있는 memory dump 기능을 이용하면 넘어온 객체가 얼마나 메모리를 먹고있나를 볼 수 있습니다. 이를 통해 실서버에서 셋팅된 Heap memory size와 데이터가 차지하는 용량을 비교했을 때, 큰 문제 없을 것 같다고한다면 진행해도 되겠죠. 실제로 실행할 때는 pinpoint 같은 APM 툴을 이용해서 JVM Heap 의 상태를 관찰해주는게 필요할 것 입니다. 다만 스마트해 보이진 않습니다.2. page 사이즈를 항상 0으로 할 수 있게 오버라이딩 한다. 항상 읽을 때 맨 앞 chunk만 바라보게 합니다. 한번 transaction 이후 지우고나서도 맨 앞을 바라보니 누락될일이 없죠. 구현체 마다 다르겠지만, MyBatisPagingItemReader 내부적으로 들고 있는 page 사이즈는 올라가더라도, 실제 쿼리 실행할 때는 늘 맨처음 기준으로만 가져오도록 하여 이 중간 이빨빠짐 현상을 피할 수 있습니다. 일반적으로 가장 쉽게 이렇게 회피를 하는 것 같습니다. @Bean @StepScope public ItemReader&lt;Order&gt; itemReader() { MyBatisPagingItemReader&lt;Order&gt; itemReader = new MyBatisPagingItemReader&lt;Order&gt;() { @Override public int getPage() { return 0; } }; itemReader.setQueryId(\"query-name\"); itemReader.setPageSize(PAGE_SIZE); itemReader.setSqlSessionFactory(sqlSessionFactory); return itemReader; } 3. CursorReader 를 통해서 읽는다. CursorReader 는 Driver 와 DB 가 둘다 지원이 되어야 쓸 수 있습니다. mysql 인 경우 useCursorFetch=true 옵션을 주고 connection 을 형성해야 동작합니다. 대표적으로 JdbcCursorItemReader 같은 것이 있는데, 커넥션을 계속 이어둔 상태로 streaming 같이 메모리엔 일정 숫자만큼만 쭉쭉 db 로 부터 빨아들이고 다 처리하면다음 것을 가져오는 식 입니다. 이에 앞에 데이터가 지워지는 것과 상관없이 적은 메모리로 누락없이 처리 할 수 있습니다. 다만 트랜잭션을 길게가져가게되고, wire shark 로 살펴볼 시 네트워크 통신도 많아지며, 커넥션 타임아웃도 길게 가져가야합니다. CursorReader 에 관해선 별도의 글로 세부 서술 예정입니다.4. 그냥 몇 개 누락하더라도 job 을 여러번 돌려서 마무리 한다. ㅋㅋ 데이터 성격상 그냥 한번 지워버리고, 반드시 한번에 안 지워져도 되는 녀석들이 있습니다. 그러면 그냥 큰 고민하지말고, 여러번 job 을 돌려서 첫번째 실행 SELECT * FROM table LIMIT 0, n 이 지워줄거라고 믿어도 됩니다.. 대신 좀 자괴감은 들겠지만요.후기 chunk 기반 동작이라는걸 명심하고 배치를 개발하면 사실 쉽게 파악할 수 있는 이슈입니다. 하지만 바쁘기도하고… 빠르게 개발하다보면 하기도 쉬운 실수로 보이네요.." }, { "title": "Real Mongo DB 요약 (~ing)", "url": "/posts/Real-Mongo-DB/", "categories": "Blogging, Book", "tags": "database, mongodb", "date": "2022-07-21 09:00:00 +0000", "snippet": "1. MongoDB1.1 데이터베이스 트렌드 오라클 RDBMS, MS SQL Server 라이센스 비용 때문에 빡쳐서 -&gt; 다들 MySql 로 Run (facebook, google, twitter) 구글은 Mysql 쓰다가 Bigtable(No SQL) + Spanner(분산 트랜잭션) 연구 시작 페북은 카산드라를 버리고 트위터 링크드인과 MySQL 을 발전시킨 -&gt; WebScaleSQL 개발함 결국 여기까지 트렌드만 보면, ‘확장성’. MySQL 이 부족한 Scalability 를 다들 찾고 있음을 느낄 수 있음. Maria DB 도 2014년 이떄쯤 등장 2012년 쯤부터 카산드라 등 NoSQL 성장함. 그러나 결국 남은건 HBase (GFS, Bigtable 기반) + MongoDB 그러나 2000년대 후반까진 NoSQL DBMS 들이 기능 빵꾸가 너무 많아서 상용으로 쓰긴 힘들었음. 카산드라 + HBase 는 자바 기반 NoSQL 로 GC 로 인한 성능 저하가 늘 여전히 고민. 입지가 줄어든편 Mongo 트랜잭션지원, 분산처리, 재해복구, 샤딩 &amp; 리밸런싱, 데이터복제 자동복구 지원 WiredTige 엔진 장착이후 부터 날개달기 시작함. 1.6 아키텍쳐2. Storage Engine2.1 MMAPv1 이제 사실 거의 안씀. 초창기 몽고의 스토리지 엔진 자체 구현 캐시가 없고, os layer 의 캐시를 사용하는데 이는 system call 을 해야해서 느림 os 자체 캐시시스템의 설정을 건드는 것 또한 사이드이펙트가 있을 수 있어서 적용 어려움 그래도 사실상 고대 몽고의 엔진이어서 다룬 느낌. 몽고설정에서 engine: mmapv1 입력시 적용됨 데이터 파일 구조, 데이터 파일당 사이즈 정도 설정하는게 있어서 성능 튜닝은 딱히 할 것이 없음." }, { "title": "Spring Batch Chunk Oriented & Transaction", "url": "/posts/spring-batch-chunk-transaction/", "categories": "Blogging, Spring", "tags": "spring, spring-batch, transaction", "date": "2022-07-15 09:00:00 +0000", "snippet": "Spring Batch Chunk Oriented &amp; Transaction 맨날 StepBuilder.java 나 JobBuilder.java 로 기계적으로 job 을 만들다 보면, 너무나 많이 추상화 된 프레임워크에 의해 가축이 되는 느낌을 받습니다… Spring Batch 는 chunk 단위로 데이터 처리를 합니다. Job - Step - Tasklet - Reader + Writer + Process 계층을 이루고 있는 점. 그리고 Tasklet 내 chunk 단위 처리 중 에러가 발생하면 롤백 한다는 내용은 누구나 알고 있습니다. 일단 jobLauncher 가 Job 을 시작하는건 알겠는데 어떻게 R + P + W 순으로 동작을 하는걸까 (이하 RPW) 그리고 분명히 spring-tx 의 TransactionManager을 이용할거고, 트랜잭션 처리를 할 것 인데 어느 타이밍에 트랜잭션이 동작하는지 모르겠다는 의문이 들었습니다. writer 에 쓰기전에 transaction 을 실시할까? 그러면 processor 에서 뭔가 insert 한건 롤백이 안될 것 같은데… 그럼 read 할 때부터 transaction 을 거는건가? 뭣하러 그때부터 걸지? writer 를 Composite Writer 를 써서 멀티 database 에 writer 를 하는 경우는 무엇을 해야할까 등등의 의문을 가졌습니다. 이걸 확인하기 위해선 크게 두 줄기로 파봤어야합니다.1. Job 은 어떻게 만들어지는가 - Chunk Oriented 구현 방식에 관한 이야기 뭔가 writer 의 write() 를 호출하기 전후로 트랜잭션 코드가 있을것 같은 느낌을 받았습니다. 그래서 Job, Step 구성하는 소스를 까봐야했죠. @Configuration@RequiredArgsConstructorpublic class JobConfig { private final JobBuilderFactory jobBuilderFactory; private final StepBuilderFactory stepBuilderFactory; @Bean public Job sampleJob(Step sampleStep, JobExecutionListener jobExecutionListener) { return jobBuilderFactory.get(JOB_NAME) .start(sampleStep) .listener(jobExecutionListener) .preventRestart() .build(); } @Bean @JobScope public Step sampleStep(ItemReader&lt;BeforeDomain&gt; reader, ItemProcessor&lt;BeforeDomain, AfterDomain&gt; processor, CompositeItemWriter&lt;AfterDomain&gt; writer) { return stepBuilderFactory.get(JOB_NAME.concat(\"Step\")) .&lt;BeforeDomain, AfterDomain&gt;chunk(CHUNK_SIZE) .reader(reader)//user_reward .processor(processor) .writer(writer) .build(); }} 흔한 Job 설정이나 Job 을 만들 떄 쓰는 JobBuilderFactory, StepBuilderFactory 를 보겠습니다. 이 Bean 들은 @EnableBatchProcessing 활성화 시, SimpleBatchConfiguration.java 를 통해 자동으로 생성됩니다. StepBuilderFactory.java 를 살펴보면, transactionManager 를 주입받아놓고, get 할 때 같이 넣어줘서 만드는 것을 알 수 있습니다. 원한다면 .transactionManager() 를 통해 기본말고 커스텀하게 집어넣을 수 있죠. public StepBuilderFactory(JobRepository jobRepository, PlatformTransactionManager transactionManager) { this.jobRepository = jobRepository; this.transactionManager = transactionManager; } public StepBuilder get(String name) { StepBuilder builder = new StepBuilder(name).repository(jobRepository).transactionManager( transactionManager); return builder; } StepBuilder 가 transactionManager 를 넣어준다는건 알았으니, 뭔가 트랜잭션 관리를 잘 해줄거라는건 보이긴하고, 그럼 RPW 는 실제로 어떻게 구성이 되는지 알아보기 위해선 조금 더 StepBuilder 를 파봐야합니다. StepBuilder.build() 에선, 어느 순간 createTasklet() 이라는걸 호출하게됩니다. 결국 RPW 도 하나의 Tasklet 으로 구성이 되는거고, Step 은 Tasklet 을 품고 있는 우리가 아는 구조가 되나봅니다. @Override protected Tasklet createTasklet() { ... SimpleChunkProvider&lt;I&gt; chunkProvider = new SimpleChunkProvider&lt;&gt;(getReader(), repeatOperations); SimpleChunkProcessor&lt;I, O&gt; chunkProcessor = new SimpleChunkProcessor&lt;&gt;(getProcessor(), getWriter()); ChunkOrientedTasklet&lt;I&gt; tasklet = new ChunkOrientedTasklet&lt;&gt;(chunkProvider, chunkProcessor); ... return tasklet; } 다 생략하고 chunkProvider 에 reader 를 넣고, chunkProcessor 에 processor + writer 를 집어넣어 ChunkOrientedTasklet.java 를 만들게 됩니다. 결국 이 녀석이 핵심인것 같습니다. 내부 execute 코드를 살펴봐야했는데 chunkProvider 의 실제 구현체 SimpleChunkProvider.java 를 보면 우리가 아는 Reader 와 크게 다르지 않습니다. 그런데 SimpleChunkProcessor 는 특이합니다. //ChunkOrientedTasklet.java @Override public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) throws Exception { ... // 처리해야할 데이터 Chunk&lt;I&gt; inputs = (Chunk&lt;I&gt;) chunkContext.getAttribute(INPUTS_KEY); if (inputs == null) { inputs = chunkProvider.provide(contribution); //더이상 인풋이 없을때까지 될 때까지 계속 읽는 영역 if (buffering) { chunkContext.setAttribute(INPUTS_KEY, inputs); } } //SimpleChunkProcessor chunkProcessor.process(contribution, inputs); //process + writer chunkProvider.postProcess(contribution, inputs); ... } //SimpleChunkProcessor.java @Override public final void process(StepContribution contribution, Chunk&lt;I&gt; inputs) throws Exception { initializeUserData(inputs); if (isComplete(inputs)) { return; } // Processor 가 지지고볶음 Chunk&lt;O&gt; outputs = transform(contribution, inputs); contribution.incrementFilterCount(getFilterCount(inputs, outputs)); // Wirter 가 지지고볶음 write(contribution, inputs, getAdjustedOutputs(inputs, outputs)); } 대충 정리해보면 chunk 단위로 읽을 떄서 있습니다. spring batch reference 에 가니 정확하게 알려주네요. 이로써 spring batch 는 ChunkOrientedTasklet.java 를 유연하게 만들어서 RPW 를 주입받고, 이를 통해 chunk 지향처리를 진행함을 알 수 있었습니다. 하지만 정작 궁금했던 Transaction 이 걸리는 타이밍에 관해서는 더 들어가도 위 코드 분석으로는 알 수 없었습니다. 어디서 거는건지 알 수가 없네요.2. Job 은 어떻게 실행되는가 - 트랜잭션에 관한 이야기 Transaction Manager 를 stepBuilder 에서 주입했는데, chunk 단위 처리를 하는 Tasklet 상 코드를 볼 수 없었습니다. 제가 처음 예상했던 그림은 아래와 같았는데 여지없이 빗나가서 Job 실행단계를 파봐야함을 느꼈습니다. //ChunkOrientedTasklet.java 내read()트랜잭션매니저.doTransaction startprocess()writer()트랜잭션매니져.commit() Job을 실행할 때 JobLauncher.launch() 를 통해 실행을 합니다. 계속 메서드를 따라 들어가다보면, TaskletStep -&gt; doExecute 에서 아래를 볼 수 있습니다. new TransactionTemplate(transactionManager, transactionAttribute).execute(new ChunkTransactionCallback(chunkContext, semaphore)); Step 의 ChunkContext를 spring-tx 의 TransactionTemplate 위에서 동작 시키는 겁니다. 요걸 Callback 형태로 실행을 해서 따라가기가 좀 힘들긴한데, 결국 step 의 transactionManager 위에서 Chunk Tasklet 자체가 실행됨을 볼 수 있습니다. 결론은 나왔습니다. read 할 때부터 transaction 이 걸리는거고, 중간 processor에서 insert 를 하건 뭘하건, 어디든 한 곳에서 뻑나면 모두 rollback이 될 수 있다는걸 소스를 통해 확인했습니다. //TaskletStep.doInTransaction : 트랜잭션 안에서 이 일을해라... @Override public RepeatStatus doInTransaction(TransactionStatus status) { TransactionSynchronizationManager.registerSynchronization(this); ... result = tasklet.execute(contribution, chunkContext); //여기! ... } 후기 왜 제 예상대로 만들지 않고, 실행단계에서 Chunk 단위로 처리할때 복잡한 콜백 패턴으로 만든건지 생각을 해봣는데, 결과적으로 이게 더 분업에 효율적이고 모듈화를 잘 된 케이스라고 보입니다. 왜냐면 1번 Job 을 어떻게 구성하는가 영역은 말그대로 Job 을 “구성” 만의 개발만하면 되는 것이고, 2번 Job은 어떻게 실행되는가 를 구현하는 이들은 “실행”단 개발에 집중할 수 있기 떄문이 아니었을가 싶네요. 결국 스프링도 여러 개발자들의 협업에 의해 개발 되므로, Runner 단에서 트랜잭션 처리 개발과 순수 Job 구성단의 분업을 깔끔하게 하려고해서 그러지 않았나? 생각이 듭니다. 이건 시간날때 한번 batch repo 에 질문해볼 수 있을 것 같네요. 긴 글 읽어주셔서 감사합니다." }, { "title": "Google Cloud Platform GCP 정리", "url": "/posts/Google-Cloud-Platform/", "categories": "Blogging, DevOps", "tags": "cloud, gcp, google-cloud-platform", "date": "2022-07-13 09:00:00 +0000", "snippet": "개요 전통적인 IT(온프레미스): 기업이 할거 다해야함 -&gt; IaaS -&gt; PaaS -&gt; 그리고 SaaS : 구글클라우드 자체. 그래도 클라우드도 첼린지할 이슈가 많음. 보안 : 제2 전문업체에 기업 정보가 다 올라감. 클라우드가 털리면 데이터 전부 유출. 인력 자원이 별로 없다… GCP 의 특장점. 타 클라우드와 비교해볼때 편리한 메시징 서비스 - GCP 는 Pub/Sub 으로 모든 내용 수행 가능 - 공식 지원 pub/sub 최고의 머신러닝 서비스 - 파이썬 자바몰라도 SQL 문으로 ML 모델 생성 가능 - Speech toText - Vision AI 감정 텍스트분석 안전하고 유연한 네트워크 - 자체 네트워크 라인. - 전역적인 VPC 저렴함 리전이 많음. 28개, 85개의 가용영역권한 Im 매니지먼트을 통해 실시함. 협업 용Compute Engine 가상장비 하나 받는 거라고 생각하면됨. 최저비용이 월 만원정도 이 인스턴스를 그대로 묶어 스냅샷 가능 -&gt; 부팅디스크 항목을 설정하면 됨. -&gt; 도커 같은 느낌이지 마켓 플레이스 인스턴스 몽고, 젠킨스, 엘라스틱, 비트나미.. Deployment Manage 를 통해서 관리할 것. 인스턴스 템플릿으로 미리미리 만들어 둘 수 있음 인스턴스 그룹 : k8s auto scailing 의 활. 자동 업데이트 기능 지원. 관리형 인스턴스 그룹 : API 같은거 비관리형 인스턴스 그룹 : 로드밸런서 헬쓰체크 지원 가능 동시 배포 가능. 관리 : 시작스크립트 넣을 수 있음GCS 클라우스 스토리지. 이미지, 파일 등.. AWS S3 Owfs, 나스라고 생각하자 그냥 내가 쓰던거 서버에 마운트를 직접적으로 하는건 아니고 gsutil 도구로 관리하는 개념. 설치가 좀 귀찮은 것 같다. 한번 설치하고 인스턴스 이미지화 해두어야할듯함. VPC virtual private cloud : 사설망로드밸런서 그냥 내가 아는 그거 웹서버 만들고 -&gt; 스냅샷 -&gt; 이미지 -&gt; 인스턴스 템플릿 -&gt; 인스턴스 그룹화 해서 오토스케일쓰자 로드밸런서 생성하고 -&gt; 인스턴스 그룹 연결로 종료 stressBigquery 페타바이트 급 데이터 저장 분석용. mysql 쿼리와 동일 쿼리를 쓰다보니 접근성이 진짜 캡좋음. 누구나 쉽게 쓸 수 있음. 하둡 사용같은 허들 필요없음. 장비 관리 필요없음 웹으로 workbench 같은걸 제공함. 누구나 약간 편하게 거대 저장소를 쓸 수 있게 오픈한 상태 특징 칼럼마다 쪼개서 데이터를 저장 노 인덱스, 항상 풀스캔 칼럼마다 다른파일로 저장하기 떄문에, 데이터 저장 삭제만 가능함. 수정 불가능. insert into 3개 넣는게 2초가 걸림… 소규모 데이터 빈번하게 넣거나 업데이트하는데는 매우 좋지않은 서비스. GCP PUB / SUB 퍼블리셔 1 / 구독자 다수 특정 주제 메세지 전송하면 -&gt; 구독자가 메세지 송신함. 데이터 동기화 같은거에 쓰는듯? 서비스간 통로를 통일하는데 괜찮긴한듯. 뭐 우리가 카프카 쓰는거랑 차이는 없을것 같음. 방법 버킷 생성 -&gt; 주제 생성 -&gt; 메세지 누가 주제로보내면 -&gt; DataFlow 따라 -&gt; 빅쿼리나 스토리지에 기록 AppEngineCloud Scheduler 약간 jenkins 같이 타이머 시간마다 호출하게 해주는거 구독에 쓰기도함." }, { "title": "Spring Framework 간단한 정리 - 알고도 다시 짚자", "url": "/posts/spring-framework/", "categories": "Blogging, Spring", "tags": "spring", "date": "2022-07-09 09:00:00 +0000", "snippet": "스프링 프레임워크 레퍼런스IoC : Inversion of Control 제어의 역전 객체의 생성과 소멸 제어를 원래는 작성자가 함. new Instance 벗 스프링에서 특수한 Annotation 을 붙이거나, 직접 @Bean 등록된 객체들은 IoC Container = ApplicationContext 가 구동시 다 만들어 들고 있음. 최초 Spring 구동시 등록하는 로깅이 잘 보임. 그래서 너무 많은 Bean 을 만드는 상황이면 최초 구동속도가 느려짐… 이렇게 만들어둔 Bean 들은 DI로 사용처에 주입이 된다.DI : Dependency Injection IoC 와 긴밀하게 연결되어있는 특징 객체의 생성과 소멸을 IoC Container 가 해주는 것이고, 생성된 객체는 주입해서 사용 주입해서 사용한다는 말은, new 해서 새로 만들지 않는다는 것. DI 한 class 들 간 hash 값 비교하면 동일한것을 알 수 있음Assert.equals(this, ApplicationContext.getBean(\"myService\"))AOP : Aspect Oriented Programming 관점 지향형 프로그래밍. 비즈니스 로직에 집중을 하고, 그 외에는 별도의 방법으로 로직 살을 붙이자. 공통된 반복로직을 제거하는데 용이하게 쓸 수 있음. AOP 를 구현하는 방법은 3가지정도 원래 있음 컴파일 단계 : .class 만들 때, 조작해서 로직 집어넣음 바이트코드 조작단계 : .class 파일 만들고 메모리에 올릴때 조작도 가능 프록시 패턴 : Spring 에서 요걸 씀. 정상적으로 빌드하고 패턴을 이용해 프록시 AOP 도입 프록시 패턴에 대해 적지 않을 수 없음. 기존 코드를 건드리지 않고 새 로직을 추가하기 java code example 예를 보면 Proxy객체는 공통 interface 상속을 하고, 원래 것을 멤버변수로 들고 있음. 실행시 Proxy 객체를 주입해서 사용하면 추가된 로직 + 원래 로직 그대로 실행할 수 있어서 동작 추가 가능. 리펙토링에 적극 활용해도 좋음. @Aspect 샘플코드는 널리고 깔렸으니 생략PSA : Portable Service Abstraction 추상화를 통해 언제든 갈아낄 수 있게 한다. Controller transactionManager CacheManager예제로 배우는 스프링 입문 나는 어디까지 알고 싶은건지부터 정해야함 대충 뭔지는 암 -&gt; 중요한 개념들은 알고 개발은 개념 다 써서 할 수 있음 -&gt; [가성비 안나오는 벽] -&gt; 좀 깊게 알아서 컨트리뷰션 할 수 있는 정도 -&gt; [넘사벽] -&gt; 저자들 수준으로 다알아 가성비 안나오는 곳 까지만 파보자" }, { "title": "Spring Boot Starter", "url": "/posts/spring-boot-starter/", "categories": "Blogging, Spring", "tags": "spring", "date": "2022-07-01 09:00:00 +0000", "snippet": " spring 은 우리가 아는 DI, IoC, Pojo, AOP 특징을 가진 프레임워크 spring-boot 는 spring 프로젝트 내 단일 application 으로 동작 할 수 있도록 편의를 갖춰준 프로젝트 spring-boot-starter 는 어플리케이션 제작을 할 때 dependency 와 버저닝을 지원하기 위해 만든 boot 의 sub module. (이하 starter) starter 는 AutoConfiguration 의 지원으로 정말 대부분의 동작을 추상화 시켜버림 이는 @ConditionalOnClass @ConditionalOnBean @ConditionalOnWebApplication @ConditionalOnMissingBean 등을 이용하여, boot 시작 때 설정값들을 선택적으로 bean 등록. @Bean 으로 등록이 되면 사용자는 원하는 컴포넌트를 가이드대로 @Autowired 해서 사용하면 됨. spring-boot-starter - build.gradle 을 보면 재밌음 사실상 모든 starter 들에 다 들어 있는 고정멤버. api(project(\":spring-boot-project:spring-boot-starters:spring-boot-starter\")) plugins {\tid \"org.springframework.boot.starter\"}description = \"Core starter, including auto-configuration support, logging and YAML\"dependencies {\tapi(project(\":spring-boot-project:spring-boot\"))\tapi(project(\":spring-boot-project:spring-boot-autoconfigure\"))\tapi(project(\":spring-boot-project:spring-boot-starters:spring-boot-starter-logging\"))\tapi(\"jakarta.annotation:jakarta.annotation-api\")\tapi(\"org.springframework:spring-core\")\tapi(\"org.yaml:snakeyaml\")} spring-boot SpringApplication.java 가 들어있는 boot 의 main autoconfigure 모든 starter 의 설정 META-INF 들고 있는 모듈의 bean 을 등록해준다. " }, { "title": "Spring-data-rest 간단한 정리", "url": "/posts/spring-data-rest/", "categories": "Blogging, Spring", "tags": "spring, spring-data, spring-data-rest", "date": "2022-06-27 09:00:00 +0000", "snippet": "spring-boot-starter-data-rest spring-data-…가 하도 많아서 매우 햇갈림. spring-mvc 기반 reactive 지원 의지 없음. 이슈 링크 import 하고 repository 에 annotation @RepositoryRestResource 붙이면 controller 부터 entity 기준으로 CRUD 메서드가 생긴다. swagger 도 간편하게 붙일 수 있음. //Swaggerimplementation 'io.springfox:springfox-swagger2:3.0.0'implementation 'io.springfox:springfox-data-rest:3.0.0'implementation 'io.springfox:springfox-swagger-ui:3.0.0' @EnableSwagger2@Import(SpringDataRestConfiguration.class) //swagger 설정임.@SpringBootApplicationpublic class AdminApplication extends WebMvcConfigurationSupport {\tpublic static void main(String[] args) {\t\tSpringApplication.run(AdminApplication.class, args);\t}\t@Bean\tpublic Docket api() {\t\treturn new Docket(DocumentationType.SWAGGER_2)\t\t\t\t.select()\t\t\t\t.apis(RequestHandlerSelectors.any())\t\t\t\t.paths(PathSelectors.any())\t\t\t\t.build();\t}\t@Override\tpublic void addResourceHandlers(ResourceHandlerRegistry registry) {\t\tregistry.addResourceHandler(\"/swagger-ui/**\").addResourceLocations(\"classpath:/META-INF/resources/webjars/springfox-swagger-ui/\");\t\tregistry.addResourceHandler(\"/webjars/**\").addResourceLocations(\"classpath:/META-INF/resources/webjars/springfox-swagger-ui/\");\t}} spring-mvc 기반이기 떄문에 reactive 와 같이 쓸수 없음. @RepositoryRestResource 전처리 후처리를 위해 EventHandler @RepositoryEventHandler 를 제공함.@Slf4j@Component@RepositoryEventHandlerpublic class RadioChannelsEventHandler { @HandleBeforeCreate public void handleCreate(RadioChannels radioChannels) { log.info(\"START Radio Channel Create\"); } @HandleBeforeSave public void handleSave(RadioChannels radioChannels) { log.info(\"START Radio Channel Save\"); }} property 설정으로 base-path 지정 가능spring.data.rest.base-path: /api rest 응답결과에 default 로 @Id 가 노출이 안됨 설정으로 entity 마다 등록해줘야함. @Configurationpublic class RestConfiguration implements RepositoryRestConfigurer { /** * 응답 결과에 @Id 노출을 위한 설정. 노출을 위해선 노출할 클래스 하나하나 등록해줘야함. */ @Override public void configureRepositoryRestConfiguration(RepositoryRestConfiguration config, CorsRegistry cors) { RepositoryRestConfigurer.super.configureRepositoryRestConfiguration(config, cors); config.exposeIdsFor(RadioChannels.class); config.exposeIdsFor(RadioRecommendedChannels.class); config.exposeIdsFor(RadioUserLikedChannels.class); }}" }, { "title": "Spring Batch 간단한 정리", "url": "/posts/spring-batch-%EA%B0%84%EB%8B%A8-%EC%A0%95%EB%A6%AC/", "categories": "Blogging, Spring", "tags": "spring, spring-batch", "date": "2022-06-23 09:00:00 +0000", "snippet": "Batch DB 구조Batch 기본 flowBatch 기본 설명 step, job 등 bean 설정 한 것들은 당연히 id 가 겹쳐선 안됨. 나중것이 앞에것을 덮는 느낌. autowired 만 하다보면 헤딩할 수도 있음. job execution id : 실행시켰을 떄 생기는 아이디, 1개만 생김 job instance id : job 호출을 받으면 instance 를 만들어서 실행하게 되는데, retry 를 할 수도 있으므로 하나의 job execution id 에 여러개 job instance id 가 생길 수도 있음. chunk 단위 배치 프레임워크 job step tasklet 의 계층을 이루고 있음 tasklet 은 일반적으로 reader, processor(생략가능), writer 구조를 잡고 chunk 단위로 처리하며 commit 함. 롤백도 chunk 단위로 진행됨 reader 는 커서기반, 페이징 기반으로 구분되어있는데 별생각 없으면 paging reader 쓰면 spring batch test 에선 @Transactional 로 롤백이 안됨.결론부터 얘기하면 spring-batch 는 실행되는 각각의 상태나 변수 등을 jobRepository 를 통해 DB 에 저장을 해둡니다.이를 비즈니스 로직을 담당하는 transactionManager 와 묶어버리면 실행되는 상태나 변수 등이 한 번에 rollback 되거나 commit 되기에 rollback 이 안됩니다.애초에 시작도 안됨. java -jar 로 바로 job 실행 가능하고, web 으로 띄워서 살행도 가능은하나 jar 실행을 권장함 (리소스 다르게, 서버 필요없고, 빌드서버에서 실행가능 등등 장점) StepScope 와 JobScope 개념. 둘다 bean 을 prototype 으로 생성을 하는 것임. @StepScope를 tasklet reader 등 에 붙이는데 보통, 리턴값을 잘 설정하지 않으면 문제가 생김 인터페이스에 StepScope 붙이면 발생하는 일 : https://jojoldu.tistory.com/132 o.s.b.c.l.AbstractListenerFactoryBean : org.springframework.batch.item.ItemReader is an interface.The implementing class will not be queried for annotation based listener configurations.If using @StepScope on a @Bean method, be sure to return the implementing class so listner annotations can be used." }, { "title": "Spring Data Jdbc 후기", "url": "/posts/spring-data-jdbc/", "categories": "Blogging, Spring", "tags": "spring", "date": "2022-06-23 09:00:00 +0000", "snippet": " jdbc orm framework 배치에 써봄 spring-data-jpa 와 미묘하게 다름. 더 심플하다고 볼 수 있음. jpa 엔 lazy execution 이나 캐싱 같은것을 안에서 다 해주는데 이녀석은 즉시 실행하고, 성능적으론 jpa 보다 아쉬운 부분이 있으나 Simple 함. spring data jdbc 는 아직 delete 에 관해서는 derived Query 를 제공하지 않음entity 방식으로 지우는게 아니면 @Query @Modify 써서 native 쿼리를 실행해야함.배치는 orm 보단 쿼리를 사용하는게 효과적인것 같음….. jdbcTemplate 이나 쓰자" }, { "title": "유용한 k8s command (계속 업데이트)", "url": "/posts/%EC%9C%A0%EC%9A%A9%ED%95%9C-k8s-commands/", "categories": "Blogging, DevOps", "tags": "k8s, command", "date": "2022-06-20 09:00:00 +0000", "snippet": "원격으로 해당 팟에서 실행하기 : – 가 명령어를 갈라주는 핵심.kubectl exex [pod-name] – curl -s ip:port/logicDNS 찾기 : 내부에서 호출해야하는 cluster ip 전용.kube exec app-68bb5f68f7-xc967 – cat /etc/resolv.conf" }, { "title": "kubernetes Service 정리", "url": "/posts/Service/", "categories": "Blogging, DevOps", "tags": "k8s", "date": "2022-06-20 09:00:00 +0000", "snippet": "클라이언트에게 서비스 노출 하는 방법 : Service설정 자체는 아래의 형태로 진행함 ClusterIP 기본값 클러스터 내부에서만 통신가능한 ip 를 할당해줌. 기본 10.xx 식으로 internal ip 형태로 잡아줌. MSA 의 백엔드 컴포넌트면 요걸 사용해도 무방. NodePort master + node 의 특정포트를 통해 pod 와 연결지음 30000 ~ 32…. 몇까지 사용할 수 있는데, 모양새가 안나옴 ㅎㅎ 사용처에서 {node ip} : {포트번호} 로 사용해야하는데, DNS 등록하기도 좀 쉽지않은환경 일반 웹어플리케이션을 30000 어쩌구 붙이면서 사용하는것도 이상함… LoadBalancer 요걸로 만들면 External ip 가 할당이 되어 외부 접속이 가능함. 미리 pool 을 할당해놓고 받는 식이라 별도로 설치해서 pool 설정을 해둬야함. 클라우드 플랫폼에서 지원해줘야함.. Ingress : Service 와는 다른 구성 istio ingress GW의 근간. 서로다른 host 나 url pattern 에 따라 원하는 Service 로 떨궈줌. 근데 사실 더 중요한건 kube-proxy. 실체임. 실제 위 Service 설정을 구현함 모드는 총 2가지가 있다고 보면됨. iptables : default Service API 요청시에 iptable rule 을 master, node 1~3 에 iptable 에 등록해서 클라이언트와 Pod를 연결해줌 NodePort 로 만들시엔, 해당 포트를 열고 Listen 하고 있음. 마치 nginx 처럼. IPVS : 리눅스 커널 loadbalancing 별도 ipvs 지원 모듈을 모든 노드를 오픈하고 사용할 수 있음. 참고 k8s docs 조대협 블로그 k8s Service 강좌" }, { "title": "Node js 교과서 요약 (~ing)", "url": "/posts/Node-js-%EA%B5%90%EA%B3%BC%EC%84%9C/", "categories": "Blogging, Book", "tags": "nodejs", "date": "2022-03-27 09:00:00 +0000", "snippet": "노드 특징 자바스크립트 런타임 이벤트기반, 비동기 논블로킹 I/O 모델 V8 엔진, libuv 라이브러리 위에서 동작 싱글쓰레드 - 쓰레드 에러나면 바로 서버꺼짐. (실제론 멀티쓰레드지만, 사용자 제어는 1개) 1 core 만 사용가능. 적은 리소스 인스턴스에 적절함. CPU 작업이 많은 상황에는 부적절 싱글 쓰레드 논블로킹이므로, 외부 I/O (네트워크, DB) 요청에 적절함. 비동기, 리스너 Callback 등록으로 처리하는 것이 일반적. Promise 적극 활용. async / await 호출 스택, 백그라운드, 태스크 큐, 마이크로태스크 큐, 이벤트 루프 로 비동기 처리. pm2 를 활용한 멀티프로세싱. 메모리 자원 공유 X. 세션은 db 저장." }, { "title": "Neo4j Proof of Concept", "url": "/posts/Neo4j-poc/", "categories": "Blogging, Database", "tags": "database, neo4j, graphdb", "date": "2022-02-01 09:00:00 +0000", "snippet": "1. DB-Engines Ranking of Graph DBMS 22년 1월 기준. ranking 1위. enterprise 큰 돈 받고, 파는.2. 특징 자바 기반의 그래프 DB로서, 임베딩 방식과 REST 방식을 지원한다. jvm 상에서 돌기 때문에, 당연히 jvm 옵션들도 지원함. 주로 만지는 설정은 Heap memory, GC 트랜잭션을 지원하며, JTA(Java Transaction APIs)를 지원한다. 이중화를 통한 고가용성을 지원한다. ( Zookeeper 사용)= 백업/복구를 지원한다. gui 툴이 강력하다. Desktop App 도 있으며 브라우저를 Database IDE 로 사용 가능하다 몽고같은 알아서 샤딩 불가능. 모든 데이터가 단일 노드에 쓰인다. 읽기 전용 replica 를 따로 두어 성능을 보장한다. 장비 scale out 개념이 없음. 용량 부족시 scale up 으로만 해결 가능 g의 이유로 정말 큰 빅데이터를 무한히 쌓으며 처리하는 플랫폼으로는 적합하지 않음. (제한이 필요함) 3.x대 버전은 jdk 1.8 사용, 4.x대 버전은 jdk 11 사용3. ecosystem spring-boot : spring-data-neo4j : 넣고 빼고 jpa 느낌public interface PersonRepository extends Neo4jRepository&lt;Person, Long&gt; { Person findByName(String name); List&lt;Person&gt; findByTeammatesName(String name);}@Nodepublic class Person { @Id @GeneratedValue private Long id; private String name; private Person() { // Empty constructor required as of Neo4j API 2.0.5 }; @Relationship(type = \"TEAMMATE\") public Set&lt;Person&gt; teammates; public void worksWith(Person person) { if (teammates == null) { teammates = new HashSet&lt;&gt;(); } teammates.add(person); }} node : neo4j-driver4. 설정. 핵심 위주 $NEO4J_HOME/conf/neo4j.conf 로 하나의 파일에서 모든 설정을 담당한다.neo4j.conf 매우 직관적이고 주석 포함해 800줄밖에 되지 않으니 하나하나 읽어봐도 오래걸리지 않는다. 굳이 문서를 참고할 필요는 없다. jvm heap memory# heap initial, max 는 일반 was 설정과 같이 동일하게 설정하는 것이 좋음. 동적 변경은 OOM 발생 가능성 및 GC 가능성 증가dbms.memory.heap.initial_size=4gdbms.memory.heap.max_size=4g cache# graph data, index data를 메모리에 로드하여 disk io를 줄이는 캐싱이다.# 일반적으로 disk io를 줄이기 위해, db 실행시 warm up을 통해 많은 양의 데이터를 memory에 상주시킨다.# jvm heap 메모리와 관련이 없고 Native Memory 영역, OS로부터 직접 할당받는 영역으로 알아서 사이즈는 동적으로 변한다. GC 가 영향을 미칠 수 없는 영역이다.dbms.memory.pagecache.size=40g# n 개의 Execution plans 를 캐시.# Execution plans 은 Cypher Query 를 구성하는 operator 의 트리구조를 의미함.# 결과를 캐싱하는건 아니고 plan tree 를 캐싱해서 실행을 조금더 빠르게 한다는 의미로 생각하면 됨.dbms.query_cache_size=1000 neo4j-admin memrec 커멘드를 이용하여 메모리 설정 추천을 받을 수 있다 Network connector configuration 관련# 따로 설정을 하지 않는다면, neo4j 는 로컬에서 접속만 가능한 상태다.# 아래 설정을 변경해 줌으로서 외부에서 remote 로 붙을 수 있게 됨.# 받은 서버에 neo4j 설치 이후 아래 설정을 변경해서,dbms.default_listen_address=0.0.0.0# ip 나 dns를 셋팅해서 사용자 접근 받을 수 있게한다고 되어있는데. 사실 좀 애매함.# 여러대 설치하느라 ip 자동 입력을 위해 shell 스크립트 사용# neo4j 구동시 shell script 사용하고 싶으면 $NEO4J_HOME/bin/neo4j start --expand-commands 명령어 붙여서 실행해야함dbms.default_advertised_address=$(hostname -I)## 접근하기위해 사용할 수 있는 protocol 설정. Database IDE 에선 bolt 로 붙는다.dbms.connector.bolt.enabled=truedbms.connector.http.enabled=truedbms.connector.https.enabled=false5. 실 서비스에서 활용하기 위한 내용 cluster: enterprise 버전에만 존재함 neo4j 는 샤딩을 지원하지 않음. graph database 와 샤딩은 trade off 관계 by Neo4j 개발자. 구현을 할 수 있지만 속도 문제 등 다양한 문제를 고려할 떄, 어렵다 판단해서 neo4j 에서는 활용하지 않음. 모든 데이터가 단일 노드에 들어있기 때문에, read / write 성능, 장애 발생시 failover 에 대한 보장이 필요했다. core 숫자 = 2N + 1 개를 유지하면 N번의 failover 가 가능함. raft 알고리즘으로 core 중 리더를 선출하고 데이터를 받으며 서로 복제하며 sync를 맞춘다. 3개 중 어디로 데이터 넣어도 write 가능 클러스터 구성 절차 core 를 먼저 배포 read-replica 는 core 가 어떤 서버인지 설정 뒤 붙이면 자동으로 cluster에 투입된다. 상황에 따라 read-replica 증설할 것. # Database mode# Allowed values:# CORE - Core member of the cluster, part of the consensus quorum.# READ_REPLICA - Read replica in the cluster, an eventually-consistent read-only instance of the database.# To operate this Neo4j instance in Causal Clustering mode as a core member, uncomment this line:dbms.mode=CORE# Expected number of Core servers in the cluster at formationcausal_clustering.minimum_core_cluster_size_at_formation=3# Minimum expected number of Core servers in the cluster at runtime.causal_clustering.minimum_core_cluster_size_at_runtime=3# A comma-separated list of the address and port for which to reach all other members of the cluster. It must be in the# host:port format. For each machine in the cluster, the address will usually be the public ip address of that machine.# The port will be the value used in the setting \"causal_clustering.discovery_listen_address\".# 최초로 통신할 코어들 ip를 투입한다. 운영중 추가하는 core instance 는 운영중 추가해도 됨.causal_clustering.initial_discovery_members=10.106.163.198:5000,10.106.156.73:5000,10.106.221.226:5002# READ_REPLICA - Read replica in the cluster, an eventually-consistent read-only instance of the database.dbms.mode=READ_REPLICAcausal_clustering.minimum_core_cluster_size_at_formation=3causal_clustering.minimum_core_cluster_size_at_runtime=3# 여기엔 core instance ip 만 작성해야함causal_clustering.initial_discovery_members=10.106.163.198:5000,10.106.156.73:5000,10.106.221.226:5002 fabric 여러 neo4j cluster 로 routing 해주는 개념. neo4j 에서는 sharding 이라고 소개를 하긴 하지만, 사실은 개발자에의해 논리적으로 나눠진 다른 datasource 간 Routing 이라고 보는것이 맞고, elastic 같은 것 처럼 cluster node 추가, shard rebalancing 같은 기능은 없어서 진정한 의미의 데이터 sharding 이라고 하긴 어렵다. 서로 관계 짓지 않고, 별도의 데이터로 저장하여 UNION 하는 방식을 지원하나, 개발복잡도가 높아질 것으로 사료됨. 사용성이 떨어지는 것으로 보임. mysql 은 다른 database 끼리 join 이나 쿼리를 동시에 처리할 순 없지만, 아래와 같은 쿼리로 함께 데이터 가져오는 것은 가능하다 # neo4j.conf Fabric configfabric.database.name=fabricfabric.graph.0.uri=neo4j://localhost:7687fabric.graph.0.database=neo4jfabric.graph.0.name=neo4jfabric.graph.1.uri=neo4j://localhost:7687fabric.graph.1.database=paymentsfabric.graph.1.name=payments# u:User 2명, a:Address, s:SSN 만들고 각각 [HAS_ADDRESS], [HAS_SSN] 로 연결USE fabric.neo4j;CREATE (u:User{uid:1234,name:\"Andy\"});CREATE (u:User{uid:7890});CREATE (a:Address{street:\"2985 Finwood Dr\",city:\"Freehold\",state:\"NJ\"});CREATE (s:SSN{num:\"321-7654-098\"});MATCH (u:User),(a:Address)WHERE u.uid=1234 AND a.street=\"2985 Finwood Dr\"CREATE (u)-[:HAS_ADDRESS]-&gt;(a);MATCH (u:User),(s:SSN)WHERE u.uid=1234 AND s.num=\"321-7654-098\"CREATE (u)-[:HAS_SSN]-&gt;(s);# fabric payment db 에 노드 3개 만들고, transaction 이어붙임USE fabric.payment;CREATE (u:User{uid:1234});CREATE (t:Transaction{tid:\"t001\",amt:10,vendor:\"amc\"});CREATE (t:Transaction{tid:\"t002\",amt:5,currency:\"USD\",vendor:\"strbcks\"});MATCH (u:User),(t:Transaction)WHERE u.uid=1234CREATE (u)-[:HAS_TRANSACTION]-&gt;(t);# fabric 활용한 query 샘플CALL{\tUSE fabric.neo4j\tMATCH (u:User)-[:HAS_SSN]-&gt;(s:SSN)\tRETURN u.uid as userId, u.name as uname, s.num as ssn}CALL {\tUSE fabric.payments WITH userId MATCH (u:User)-[:HAS_TRANSACTION]-&gt;(t:Transaction) WHERE u.uid = userId RETURN t.tid as transactionID, t.amt as Amount,t.vendor as Vendor}RETURN uname,ssn,transactionID,Amount,Vendor monitoring# prometeous 로 neo4j merics export 가 가능함 관련 설정# prometeous 알아서 설치 후, 구동 시킨 뒤metrics.prometheus.enabled=truemetrics.prometheus.endpoint=localhost:2004 장비 가용량 계산 노드 프로퍼티는 5개, 관계는 2개씩, 노드하나는 15B, 관계하나는 34B, 프로퍼티하나는 41B 라 계산하면 대충 나옴. ex). 4억 개 노드, 2억개의 관계 = 150g 유지보수 입장에서, 버전업 운영중 db 버전업하는 사례가 많지는 않지만 치명적인 오류가 있을수도 있으니…. 체크리스트 다 체크하고 클러스터 전부 내리고 업데이트하고 올리기. cluster 를 사용할 경우 순단없이 하나씩 업데이트하면 되나, 개발자가 직접 메뉴얼 보며 진행해야함. 6. 비용 싯가 : 구글링해서 본 가격은 연 7000만원 정도이나, 서비스 사이즈 따라에 다르기 떄문에 정확히는 문의해보아야함. 연 1억이라 생각하고 있으면 될 듯. ongdb : neo4j enterprise 를 오픈소스화 하여 무료로 풀린 graph db.7. 그 외 읽어볼 내용 docker &amp; kubernetes" }, { "title": "dbcp pool 설정에 관해서", "url": "/posts/dbcp-pool-setting/", "categories": "Blogging, Database", "tags": "database, dbcp", "date": "2022-01-26 09:00:00 +0000", "snippet": "메인DB mysql connection pool mysql 뿐만아니라 모든 db는 db 쪽에서 client connection pool 설정을 갖는다. 사용자가 아무리 많은 connection 맺을라고해도, 결국엔 client connection pool 이상을 넘지 못한다. 넘는 경우 연결을 만들 수 없다며 에러 받고 db access 불가능함. master 기준 현재 평시 6,500, 피크치 7,000 로 보임근데 이것보단 dbcp 의 maxActive 수치가 적절히 셋팅되어있는지가 더 중요함. 컴포넌트는 보통 늘고 있고 점점 autoscale (scale out) 기술을 적용하니 높은 트래픽인 경우, db connection 은 계속 증가함. 각각의 컴포넌트는 어느 정도 수치 로 제어할 필요는 있음. (물론 인프라 시스템상 알아서 늘어나긴하지만..) 컴포넌트 dbcp maxActive 의 합 &lt;= mysql connection Pool 설정 무분별한 코드 복붙보다는 작은 컴포넌트는 max Active 값을 줄여서 미리 장애방지 쓰레드 Pool 숫자와도 밸런스 맞추는것이 필요함. tomcat thread 숫자는 10인데, connection pool 이 50인건 의미가 없음 tomcat thread 숫자 &gt;= dbcp 가 바람직하나 그 차이가 큰 건 별로 tomcat thread(2048) &gt; dbcp maxActive(180)" }, { "title": "react-three-fiber 로 야구 중계 만들기", "url": "/posts/react-three-fiber-%EB%A1%9C-pts-%EB%A7%8C%EB%93%A4%EA%B8%B0/", "categories": "Blogging, React", "tags": "nodejs, react, threejs, react-three-fiber", "date": "2021-03-05 09:00:00 +0000", "snippet": "0. 결과물 부터 Threejs : 웹 브라우저에서 애니메이션 3차원 컴퓨터 그래픽스를 만들고 표시하기 위해 사용되는 크로스 브라우저 자바스크립트 라이브러리 React-Three-Fiber: React에서 Threejs 를 선언적, 재사용성 있게 개발할 수 있는 라이브러리. Threejs 의 React 버전웹 개발자가 그래픽스 작업을 할 일이 많지 않으나, 기회가 있을때 쟁취하여 작업하게 되었습니다.대학때도 제일 재밌게 공부했었는데 여전히 너무 재밌네요.정리하는 느낌으로 쓰자니 길어질것 같아 그나마 잘 읽히고 사연이 있어 보이게 스토리텔링으로 글을 구성했습니다.1. 발단 대부분의 페이지는 걍 api 호출해서 데이터 받고 ui 그리고 event handler 붙이면 끝인데,,, 그래픽스 작업을 하고 싶….2. 일단 페이지 구조보단, 적용할 기술부터 파악했어야 했습니다.먼저 일반 threejs 와 react-three-fiber정육면체 하나가 (0, 0, 0) 에서 뱅글뱅글 돌고있는 동일한 스펙의 화면으로 비교를 해보겠습니다.ㅋ Threejs &lt;script&gt; //scene 만들고 카메라 만들기 const scene = new THREE.Scene(); const camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.1, 1000 ); const renderer = new THREE.WebGLRenderer(); renderer.setSize( window.innerWidth, window.innerHeight ); document.body.appendChild( renderer.domElement ); //cube를 만들때 geometry, material를 선언하고 cube 에 넣은 뒤 scene 추가 const geometry = new THREE.BoxGeometry(); const material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } ); const cube = new THREE.Mesh( geometry, material ); scene.add( cube ); camera.position.z = 5; const animate = function () { requestAnimationFrame( animate ); //매 프레임 마다, 큐브에게 x축, y축기준 0.01 씩 회전을 줌 cube.rotation.x += 0.01; cube.rotation.y += 0.01; renderer.render( scene, camera ); }; animate();&lt;/script&gt; React-Three-Fiber (이하 react 라고 그냥 하겠습니다.)import ReactDOM from 'react-dom'import React, { useRef, useState } from 'react'import { Canvas, useFrame } from '@react-three/fiber'function Box(props) { //Box 참조를 위함 const mesh = useRef() const [hovered, setHover] = useState(false) const [active, setActive] = useState(false) // 여기가 돌리는 것임. useFrame hook 을 이용 useFrame((state, delta) =&gt; (mesh.current.rotation.x += 0.01)) return ( &lt;mesh {...props} ref={mesh} scale={active ? 1.5 : 1} onClick={(event) =&gt; setActive(!active)} onPointerOver={(event) =&gt; setHover(true)} onPointerOut={(event) =&gt; setHover(false)}&gt; &lt;boxGeometry args={[1, 1, 1]} /&gt; &lt;meshStandardMaterial color={hovered ? 'hotpink' : 'orange'} /&gt; &lt;/mesh&gt; )}ReactDOM.render( &lt;Canvas&gt; &lt;Camera/&gt; &lt;ambientLight /&gt; &lt;pointLight position={[10, 10, 10]} /&gt; &lt;Box position={[-1.2, 0, 0]} /&gt; &lt;/Canvas&gt;, document.getElementById('root'),)느낌만 보면 아시겠지만, threejs 의 경우 뭔가 줄 글을 보는 느낌입니다.scene 을 만들고, geometry(모양) 와 material(색) 을 합치며 Box mesh를 만들어내고,원하는 위치에 갖다 놓는걸 소설책 읽듯이 읽어갈수 있습니다.다만 문제는 분명히 소스코드 내용이 길어질수록 아무리 코드를 잘 분리하더라도 앞에 것을 까먹기 떄문에…분명히 가독성 및 이해도가 떨어질 것입니다.react 에선 마지 unity 게임프로그래밍 하듯이,Canvas 안에 카메라넣고, 빛넣고 박스넣고,박스는 내부적으로 boxGeometry, meshStandardMaterial 가지며react 컴포넌트 답게 각각은 상태관리를 합니다.3. 공 날아오는 것의 구현 공의 xyz시작위치 + xyz축 별 초기속도 + xyz축 별 가속도 만 있으면 기본적인 등가속도 운동 공식을 활용하여 원하는 순간 위치를 알아낼 수 있습니다. const displacement = (p: number, v: number, a: number, t: number) =&gt; p + v * t + (1 / 2) * a * t * t const velocity = (v: number, a: number, t: number) =&gt; v + a * t 투구 궤적 = 공 + 궤적 이므로 아래와 같이 구성했고,, 공의 위치와 속도, 궤적 좌표를 매 프레임 마다 상태 업데이트를 해줍니다. const startPosition = new THREE.Vector3(pitch.x0, pitch.z0, -pitch.y0);const startVelocity = new THREE.Vector3(pitch.vx0, pitch.vz0, -pitch.vy0);const startAcceleration = new THREE.Vector3(pitch.ax, pitch.az, -pitch.ay);const [trajectory, setTrajectory] = useState&lt;Vector3[]&gt;([]);const [position, setPosition] = useState&lt;Vector3&gt;(startPosition);const [velocity, setVelocity] = useState&lt;Vector3&gt;(startVelocity);// 매 프레임 속도와 위치 궤적 추가useFrame((state, delta) =&gt; { const newPosition = calculatePositionAtTime(position, velocity, acceleration, delta * velocityRatio,); const newVelocity = calculateVelocityAtTime(velocity, acceleration, delta * velocityRatio); setPosition(newPosition); setVelocity(newVelocity); setTrajectory([...trajectory, newPosition]);}); return &lt;&gt; &lt;Ball position={position} color={0xffffff} /&gt; &lt;BallTrajectory trajectories={_.uniqWith(trajectory, _.isEqual)} color={colorMap.trace} /&gt; &lt;/&gt; 공 상태중 위치만 업데이트 하는것이기 떄문에 rerender 할 때 공의 위치만 정확하게 변화하여 그려질 것입니다.4. 공을 여러개 그리기 데이터는 3개가 한번에 내려오는데 공 3개를 동시에 발사하는게 아닌 순차적으로 공을 발사하는 기능이 필요했습니다. 스크린야구장 가면 있는 PitchingMachine 컨셉을 이용했습니다. PitchingMachine 은 실제 화면에 그릴 renderingQueue와 waitingQueue 를 배열로 가지고 있고, Api로 받아온 데이터는 하나씩 waitingQueue 에 집어넣습니다. 그리고 timer 로 1초마다 waitingQueue에서 pop 한 뒤 renderingQueue 로 밀어넣기로합니다. const PitchingMachine = ({fireAllOneTime, pitchingDelay,}: PitchingMachineProps) =&gt; {const [waitingQueue, setWaitingQueue] = useRecoilState(PitchingMachine.waitingQueue);const renderingQueue = useRecoilValue(PitchingMachine.renderingQueue);const moveOneByOneToRenderingQueue = useRecoilCallback( PitchingMachine.moveOneByOneToRenderingQueue,);useEffect(() =&gt; { // 공 밀어넣는 과정. const pitchUnits: PitchUnit[] = []; for (const i in batter.textOptions) { const value = batter.textOptions[i]; pitchUnits.push({ textOption: value, ptsOption: pts }); } setWaitingQueue(pitchUnits);}, [batter.ptsOptions.length, batter.no]);// delay 마다 한번씩 공 발사해줌.useInterval(() =&gt; { const first = moveOneByOneToRenderingQueue();}, pitchingDelay);// reneringQueue 에 있는걸 꺼내서 그리자~return ( &lt;&gt; {renderingQueue.map((value) =&gt; ( &lt;Pitch key={value?.ptsOption?.pitchId} pitch={value?.ptsOption} colorMap={PtsDrawConst.BALL_COLOR_MAP(value?.textOption?.pitchResult)} //볼이면 초록 스트라이크면 노랑 같은식.. /&gt; ))} &lt;/&gt;);}; 5. 카메라 자유도를 제거하고 ㅠㅠ 마크업 붙이기 3d로 카메라 돌리면서 공 궤적을 자유롭게 볼 수 있도록 개발을 했지만….. 스펙에 의해 카메라는 포수 시점으로 고정이되고, 이전 투구도 볼 수 없게 됩니다. 캔버스 위로 선수 마크업 + 경기장 마크업, 이닝정보 마크업 붙이는 노가다를 실시하여 결과물을 완성합니다. 데이터 fetch 하는 모듈은 따로 선언하여 가져온 pts 정보는 PitchingMachine의 상태만 업데이트 해주고, 문자 중계데이터 정보는 하단에 별개의 모듈로 데이터를 내려주고, PitchingMachine 은 자신이 들고있는 공 그리기에 충실합니다. 서비스 스펙 맞추느라 코드는 조금 지저분해졌지만 역할은 명확하게 나뉘어있습니다.6. 성능 mesh 의 조각이 많아질수록 화면 그리는게 힘듭니다.특히 반응형으로 만드는 만큼, webgl 을 소화할 수 있으나 저사양폰은 브라우저가 멈추는 상황도 있었습니다. 궤적을 그리는데 사용되는 CatmullRomCurve3 가 성능 저하의 원인이었는데요,조금 각져보이더라도, 좀 메쉬 숫자를 줄여 대응 기기까진 동작할 수 있게 구현했습니다.7. 후기 다 작업하고 나니 threejs 결과물 보다 react로 그리도록 작업한 것이 코드양 및 가독성에 훨씬 좋았습니다." }, { "title": "ElasticSearch 1년간 운영하며", "url": "/posts/ElasticSearch-1%EB%85%84%EA%B0%84-%EC%9A%B4%EC%98%81%ED%95%98%EB%A9%B0/", "categories": "Blogging, Database", "tags": "database, elasticsearch, sharding", "date": "2020-06-09 09:00:00 +0000", "snippet": "검색을 하지않는 이상, 결국 es 는 로깅 + 조회 용일뿐 데이터 가공한걸 넣고 쓰는용으로는 맞지않다. 가공은 다른곳에 저장하고, 순정 log로 보고 편하게 쌓고 보고싶을 떄 유용하다.별 생각없으면 적용하면 좋은 부분 index 는 가능하면 시간, 날짜 기반으로 설정할 수 있도록 하고, life cycle management 기능을 이용해 적당한 날짜가 지나면 삭제해준다. 같은 데이터 포맷이면 같은 index로 쌓일 수 있도록 한다. =&gt; 이런 이유로 모든 nginx 로그 하나로 통합하는게 이득 index-template 은 무조건 설정해서 효율적으로 index를 관리하자. 트래픽이 적은 index의 경우 hot 노드를 처음부터 쓰지않고 warm 으로 들어가게 하면 hot node shard 가 well balanced 해지기 떄문에 좋다. 이는 다 섞어서 쓰게 되는경우, num of shards 를 비슷하게 가져가려고하는 elastic search rebalance 정책상 특정 노드에 트래픽이 몰리는 상황이 올 수 있다. 트래픽 많은 index 들은 shard 숫자를 적절히 셋팅해 사용 node를 묶고, 적은 노드들은 warm으로 보내 서로 독립적으로 돌도록해버린다. es는 RESTful Api를 지원하기 떄문에 언제 어디서든 조회가 너무나도 강력하다. {endpoint}/{원하는index-pattern}/_search 로 어디서든 데이터 조회가 가능하다. spring-data-elastic 의 RestClient.java 로 권장되긴 하지만, 복잡한 설정 필요없이 일반 RestTemplate.java 를 사용해도 아주 편하게 조회해올 수 있다. String url = UriComponentsBuilder.fromHttpUrl(ES_ENDPOINT) .path(\"/contents-news-*\") .path(\"/_search\").toUriString(); HttpEntity&lt;String&gt; entity = new HttpEntity&lt;&gt;(ES_REQUEST_BODY, makeElasticSearchRequestHeaders()); return new RestTemplate().postForEntity(url, entity, ESNewsAccessResponse.class); cpu usage에 영향을 주는 항목들 높은 트래픽 트래픽이 많아서 indexing 을 자주 하는 경우 cpu 가 튄다. 적은양의 memory size elasticsearch 는 자바로 개발되었고, mem size가 적으면 gc가 자주 일어나기 떄문에 cpu 사용률이 높아진다.이런경우 memory usage도 같이 확인해서 문제시 노드 스펙을 늘려본다. 너무 많은 양의 shard 숫자 shard 숫자가 많으면 조회시 그만큼 뒤져야할 cpu 일감이 많아져서 느려짐. 그럼 적정 숫자는 얼마인지는 운영하면서 파악을 해봐야하는데.. 샤드 갯수 정리 하나의 샤드는 가능하면 50g를 넘기지 않도록 구성한다. 클러스터 전체 샤드가 1000개 이상 되면 맛이 간다고 봐도 될 것 같다. 트래픽이 많은 index의 경우, node가 분산해서 데이터 쌓을 수 있게, shard 갯수 = cpu 코어 숫자 * 노드 수 (replica 0 일때) ex) 멀티쓰레드지원 쿼드 코어로 5개 노드가 주어지면, 2 * 4 * 5 = 40개가 이론상 빠르나.. index가 많아지면 조회시 cpu usage 가 그만큼 올라간다." }, { "title": "CustomArgumentResolver 사용법", "url": "/posts/CustomArgumentResolver-%EC%82%AC%EC%9A%A9%EB%B2%95/", "categories": "Blogging, Spring", "tags": "spring, spring-mvc", "date": "2019-08-01 09:00:00 +0000", "snippet": "문제 의식 컨트롤러에 들어오고, request 에서 뭔가를 꺼내는 기존 방식은 불편하고 필요없는 코드를 너무 많은곳에 양산하게됨. 그냥 컨트롤러 맨 앞부터 파라미터로 받으면 좋겠음. request에서 뭔가를 꺼내서 맵핑하는게 싫음설정 방법HandlerMethodArgumentResolver 를 구현한 커스텀 Resolver를 만듬public class OsoriModelArgumentResolver implements HandlerMethodArgumentResolver {\t@Override\tpublic boolean supportsParameter(MethodParameter methodParameter) {\t\treturn OsoriModel.class.isAssignableFrom(methodParameter.getParameterType());\t}\t@Override\tpublic Object resolveArgument(MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer,\t\t\tNativeWebRequest nativeWebRequest, WebDataBinderFactory webDataBinderFactory) throws Exception {\t\tHttpServletRequest httpServletRequest = nativeWebRequest.getNativeRequest(HttpServletRequest.class);\t\tOsoriModel userModel = new OsoriModel(httpServletRequest);\t\treturn userModel;\t}}스프링 설정 ArgumentResolver 에 추가함. (Java config 로 하고 싶다!!!!!!!!!)&lt;mvc:annotation-driven&gt;\t\t&lt;mvc:argument-resolvers&gt;\t\t\t&lt;bean class=\"com.osori.common.resolver.OsoriModelArgumentResolver\"/&gt;\t\t&lt;/mvc:argument-resolvers&gt;\t\t&lt;mvc:message-converters&gt;\t\t\t&lt;ref bean=\"jsonHttpMessageConverter\"/&gt;\t\t&lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt;그러면? 아래와 같이 쓸 수 있다. 이제 우리는 request 객체를 Controller 에서 안볼수 있다.@RequestMapping(value = \"/test/event/{orderId}\", method = RequestMethod.POST)public ModelAndView test(OsoriModel OsoriModel, @PathVariable String orderId) { Param param = new Param(OsoriModel.getUserId(), orderId);...}" }, { "title": "Javascript Front-end 면접문제.", "url": "/posts/javascript-%EB%A9%B4%EC%A0%91%EB%AC%B8%EC%A0%9C/", "categories": "Blogging, Front-end", "tags": "javascript, interview", "date": "2019-08-01 09:00:00 +0000", "snippet": " 이것만 다 대답할 수 있으면 된다.초급 단계 루프, if 구문, try/catch등 같은 기본 프로그래밍 문법을 아는것. 함수가 정의되고 할당되는 다양한 방법과 더욱이 익명함수를 포함하는 함수 정의법에 대한 이해. 기본 스코프 원리, global(window) 스코프 vs 객체 스코프.(closure는 제외) context의 역할과 ‘this’ 변수 사용의 이해. 객체에 대한 인스턴스화와 선언한는 것 뿐만아니라 함수를 인스턴스화 하고 선언하는 다른 방법들에 대한 이해. ’&lt;’, ‘&gt;’, ‘==’, ‘===’와 같은 자바스크립트 비교연산자들, falsy가 무엇인지, 객체와 문자열을 비교하는 작업 뿐만아니라 변환 작업들의 이해. 개체의 어트리뷰트와 함수들의 인덱싱이 실제 배열과 어떻게 다른지 이해(object 리터널 vs array 리터널).중급단계 timer들, 그것들이 어떻게 동작하고, 언제 어떻게 timer들이 유용한지, 더욱이 비동기 메서드 실행에 대한 이해. 컨텍스트 조작과 function argument passing 을 위한 ‘call’, ‘apply’같은 function application과 콜백 개념에 대한 깊은 이해. JSON표기법과 ‘eval’ 함수에 대한 이해 클로저에 대한 이해, 코드상에서 어떤 효과를 내는지, 또한 클로저가 private 변수들을 생성하기 위해 어떻게 사용되는지, (function(){})() 호출과 함께. AJAX와 객체 직렬화.고급단계 메소드의 ‘arguments’ 변수와 이것이 어떻게 arguments를 통해 함수 오버로드에 사용되는지에 대한 이해. length 속성과 arguments.callee를 통해 재귀적 호출하기. 비록 jQuery(v1.4 이후)와 Dojo에서 이것을 이용하고 있지만, ECMAScript 5 Strict Mode에서 지원하지 않고 있으므로 arguments.callee 사용은 위험할 수 있다고 지적한다. self-memoizing functions, currying, 그리고 partially applied functions들과 같은 클로저에 대한 고급이해. Function과 html DOM에 대한 prototype 확장, prototype 체인, 코딩을 최소화하기 위해 자바스크립트의 기본 객체와 함수(예. Array)를 사용하는 법. 개체 타입과 instanceof 와 typeof의 사용. 정규 표현식과 표현식 편집하기 With구문과 왜 With 구문을 사용하면 안되는지 이해. 무엇보다 가장 어려운 부분은 깨끗하고, 강력하고, 빠르고, 유지보수 가능하고 그리고 크로스 브라우징 되는 이 모든 수단들을 한데 모으는 법을 아는것이다.추가적으로 알아야 하는 사항 Dom과 그것을 효율적으로 조종하는 방식, 즉 노드의 추가, 삭제, 변경과 더욱이 텍스트 노드의 핸들링. 이것은 document fragments 같은 툴들을 통해 브라우저의 re-flow를 최소화 하는것도 포함한다. 크로스 브라우저 방식으로 DOM element로 부터 정보를 추출하는 것(예를들어 style, position, 등등.). 이와같은 것들은 jQuery 또는 Dojo 같은 프레임워크에서 훌륭하게 구현하고 있지만, CSS와 style 태그, computing style에서 정보 추출의 차이점을 이해는 것은 매우 중요합니다. 크로스 브라우저 이벤트 처리, 바인딩, 언바인딩 그리고 어떻게 원하는 callback context 이뤄내는지. 이런 것들은 프래임워크를 통해 훌륭하게 처리 되지만 IE와 W3C 표준 브라우저의 차이점을 이해해야 합니다. Expandos 대 attribute setting, 둘사이의 성능 차이와 존재하는 네이밍의 불일치. DOM 노드 추출을 위한 정규표현식. 효과적인 브라우저 기능 디텍팅과 장애 완화.자바스크립트 개발자라면 알아야 할 33가지 개념" }, { "title": "Maven 이 물고 들어가는 특정 라이브러리 체크", "url": "/posts/%EB%B9%8C%EB%93%9C%ED%95%A0-%EB%95%8C-%EB%81%8C%EA%B3%A0%EA%B0%80%EB%8A%94-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EB%B2%84%EC%A0%84%EC%B2%B4%ED%81%AC/", "categories": "Blogging, DevOps", "tags": "maven, devops", "date": "2019-08-01 09:00:00 +0000", "snippet": "문제상황javax.servlet-api 에 있는 HttpRequest.isAsync메서드가 없다고 나온다.분명히 pom.xml 엔 똑바로 버전이 써있는데 자꾸 빌드 돌리면 없는 메서드라고 테스트가 깨진다.해결원하는 dependency 트래킹을 해본다.mvn dependency:tree -Dverbose -Dincludes=javax.servlet옵션을 이렇게 주면 트리형태로 물고들어가는 dependency 모두 구경이 가능함.oscache 가 2.X대의 javax.servlet-api 라이브러리를 물고 들어가는걸 알 수 있다.결과올바르게 컴파일 잘되서 해결~먼저 선언 된게 우선순위를 갖는 것!http://ars-codia.raphaelbauer.com/2014/03/maven-pro-tip-dependency-ordering-and.html" }, { "title": "3명을 키우고 돌이켜보는 임신과 육아 준비 단계", "url": "/posts/parenting/", "categories": "Thinking, Parenting", "tags": "parenting", "date": "2019-06-05 09:00:00 +0000", "snippet": "임신하기 전준비 보건소 : 모자보건사업. 예비부부 건강검진. 여 : 첫째 때 - 오쏘몰 vitalf + 솔가 엽산, 둘째 셋째 때 - 센트룸 임산부용 + 솔가 엽산 남 : GNC 아르긴맥스운동 (같이..) 3개월 PT + 운동 땡큐부부혼전검사 및 병원 여자 - 난소나이 : “개인의 건강과 상관없이” 총량이 있어서 만 35세 이상부터, 그냥 가임력 급격히 낮아짐. 남자 - 정자운동성 : 하는 사람 많이 봤는데, 딱히 큰 문제 있는 놈을 본적은 없다. 개인적으로 그냥 계획 임신이라면 정신건강을 위해, 한 주기 끝난뒤 2,3 일뒤 산부인과 예약잡고 가임 날짜 봐달라고 초음파 하길 권함. 초음파로 난소 사이즈 보고 언제 방출되는지 확인해주고, 날짜 지정해줌. 한 2~3 개월만 임신이 안되어도 스트레스 받음 -&gt; 스트레스 받으면서 더 힘듬. 대신 한 번갈때마다 비급여 초음파 가격내야함. 7~10만원 상황봐서 병원에서 피검사 해서 호르몬 이것 저것 셋팅도 해줌. 임신한 후공부 퍼펙트베이비 시리즈 태아프로그래밍 부터 1 ~ 6 삐뽀삐뽀119 - 육아 지침서로 지정 신의진의 아이심리백과 - sub 우리동네 산부인과 유투브 - 궁금한거 찾아볼때, like 제왕절개준비 보건소 : 모자보건사업. 임부 엽산제 수령, 철분제 수령, 쿼드 검사 등 -&gt; 보건소에서는 무료지만 이후 산부인과에서 진행 대중교통용 지하철 임산부 뱃지, 임신확인서 들고 지하철 역무실 (혹은 산부인과에서 대충 비슷한걸 주는 경우도)구매 편한 운동화 임부복 : 점점 배가 나오며 속옷 및 옷 지속적으로 맞춰서 구매. 어차피 출산하고 절대 안입더라. 적당히 당근에서 줍는게 좋은거 같음. 운동 하루 1회 산책, 혹은 가벼운 헬스 초기에 12주까지 유산을 조심해야 한다는건 그냥 썰임 임상적으로 확인된 임신 중 자연유산의 빈도는 약 10~15%. 매우 빈번함. 한번이라도 일어났었으면 꼭 의사한테 얘기해야함. 8주가 대부분, 9주 이후 2~3%. 여기서 엄마의 과도한 무빙 / 실수로 유산이 일어난다는건 구라임. 그냥 유전자적으로 이슈가 있는애가 유산되는거임. 엄마 탓이 아님 출산 전구매 너무 많아서 임펙트 있는 것만 기록.자세히 궁금하다면 개인적으로 문의. 물건 브랜드 가격대 설명 넷째낳으면 쓴다 젖병소독기 유팡 25 젖병마다 자외선소독기를 못 쓰는게 있어서 확인하고 구매 X 유축기 스펙트라 14 보건소에서 빌려도줌. 기계만 있으면 되는거라, 굳이 구매 안하고 대여후 부속품만 구매 가능 ㅇ 분유제조기 브라비 30 광고를 겁나게해서 친구들 선물로 사봄. 근데 쓸모없음 ㅋㅋ X 천기저귀 5개 밤부베베 3 천기저귀지만 이불 및 타월 등 다양한 용도로 씀. 다재다능 ㅇ 가재손수건 30여개 밤부베베 선물로 잘 들어옴 필수 ㅇ 아기침대 코코내니 15 기호에 맞춰서.. 이건 100일까지밖에 못씀. 애매 똥 기저귀 쓰레기통 매직캔 3   ㅇ 카시트 싸이벡스 제로나 70 필수, 브랜드는 알아서 ㅇ 장난감세트 블루레빗 40 돌 이후 까지 가지고 놀 수 있는 장난감 다 들어있음 X 역류방지쿠선 카카오쇼핑어딘가 4 밥먹이고 눕히는용도. 필수. ㅇ 로션 - 풀세트 쁘리마쥬 20 소모품임 주기적으로 계속 나감. 능력껏..첫애는 쁘리마쥬, 셋째는 쿠팡산 저가로션 X 세탁/세척 도구 블랑 10 소모품임 주기적으로 계속 나감 X 첫 애 프리미엄으로 샀었다가, 둘째 셋째때 필요없다고 판단하여 당근해버린것. 젖병소독기 : 공간만 겁나게 차지한다. 24평 집이면 비추. 남이 사주면 쓴다. 분유제조기 : 개귀찮다 손으로 타는게 더 좋음. 출산 이후제일 중요한 키워드 : 일관성, 독립 육아의 알파이자 오메가 일관성 줏대없는게 제일 나쁨. 애가 제일 쉽게 망가짐 -&gt; 키우기 힘들어 진다. ㅈㄹ할거면 확실하게 일관되게 ㅈㄹ할 것 육아의 궁극적 목적은 독립임. 한 개체로서 사회에서 온전히 혼자 살아갈 수 있도록 하는것 교육같은 지원은 모두 독립을 위한 과정일 뿐 위험하지 않은 대부분의 일은 혼자 하도록 냅두자 공부 프랑스 육아 한 그릇 뚝딱 이유식" }, { "title": "마인드 컨트롤", "url": "/posts/%EB%A7%88%EC%9D%B8%EB%93%9C%EC%BB%A8%ED%8A%B8%EB%A1%A4%EC%9A%A9/", "categories": "Thinking, Mind-Control", "tags": "mind-control", "date": "2017-09-10 09:00:00 +0000", "snippet": "저렇게 무능력하면서 어떻게 저기까지 승진한거야?반드시 지킬 것 행동에 옮기기전 한번 더 생각하는 능력 과거의 지식이나 경험을 되살려 현재에 적용하는 능력 목표를 달성하기 위해 감정을 조절하는 능력 상황 변화에 대한 적응력 산만, 피로, 지루함을 버티면서 과제에 집중하는 능력 해야할 일을 미루지 않고 바로 시작하는 능력 일의 체계를 만들고, 중요도에 따라 우선순위화하는 능력 주어진 시간을 효율적으로 배분해 일을 완수하는 능력 목표를 달성하기 위한 인내심 자신에 대해 한 걸음 물러서서 객관화하는 능력" } ]
